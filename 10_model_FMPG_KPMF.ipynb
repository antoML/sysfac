{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# À propos de ce livret\n",
    "\n",
    "Ceci est la méthode KPMF : \n",
    "* Ce qu'est KPMF;\n",
    "* Comment implémenter KBMF en utilisant R;\n",
    "* La manière de faire de l'imputation avec un jeu de données spatiotemporel.\n",
    "Pour une compréhension en profondeur de la méthode, ainsi que les techniques de modélisation, voici les recherches liés au développement de la méthode : \n",
    "\n",
    ">Tinghui Zhou, Hanhuai Shan, Arindam Banerjee, Guillermo Sapiro (2012). **Kernelized probabilistic matrix factorization: exploiting graphs and side information.**\n",
    "\n",
    "\n",
    "La méthode implantée provient des dépôts Github : \n",
    "\n",
    "[**Dépôt 1**](https://github.com/kastnerkyle/School/blob/master/atpr/matrix_factorization.py) *version python*\n",
    "[**Dépôt 2**](https://github.com/sg3510/al_proj) *version matlab*\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Prêt-à-l'utilisation\n",
    "\n",
    "Ce livret est disponible pour tout usage d'imputation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-05T19:20:48.400176Z",
     "start_time": "2020-06-05T19:20:47.912258Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plot\n",
    "import matplotlib.cm as cm\n",
    "# from scipy.misc import lena (non utilisé - À la base cet élément servait à générer des images)\n",
    "from scipy.misc import ascent # au lieu de lena\n",
    "import scipy.sparse as sp\n",
    "import scipy.linalg as sl\n",
    "#import numpy.linalg as sl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-05T19:20:51.816791Z",
     "start_time": "2020-06-05T19:20:51.808832Z"
    }
   },
   "outputs": [],
   "source": [
    "os.chdir(\"C:/Users/amass/OneDrive/02_Education/02_Maitrise/Cours/PROJET_MAITRISE/application\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/python\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plot\n",
    "import matplotlib.cm as cm\n",
    "from scipy.misc import lena\n",
    "#To get the latest scipy (for banded matrix generation\n",
    "#sudo apt-get install python python-dev gfortran libatlas-base-dev\n",
    "#sudo pip install scipy\n",
    "import scipy.sparse as sp\n",
    "import scipy.linalg as sl\n",
    "#Example from\n",
    "#Singular Value Decomposition Tutorial\n",
    "#Kirk Baker\n",
    "#pg 17\n",
    "\n",
    "#A = np.asarray([[3,1,1],[-1, 3, 1]])\n",
    "#U,S,VT = np.linalg.svd(A, full_matrices=False)\n",
    "#S = np.diag(S)\n",
    "#A_ = np.dot(U, np.dot(S, VT))\n",
    "#print np.allclose(A, A_)\n",
    "\n",
    "def lowrank_SVD(input_matrix, approx=50):\n",
    "    U,S,VT = np.linalg.svd(A, full_matrices=False)\n",
    "    A_ = np.zeros((len(U), len(VT)))\n",
    "    print \"Running low rank SVD with:\"\n",
    "    print \"approximation rank=\" + `K`\n",
    "    print \"\"\n",
    "    for i in xrange(K):\n",
    "        A_ += S[i]*np.outer(U.T[i],VT[i])\n",
    "    return A_\n",
    "\n",
    "def PMF(input_matrix, approx=50, iterations=30, learning_rate=.001, regularization_rate=.1):\n",
    "    A = input_matrix\n",
    "    Z = np.asarray(A > 0,dtype=np.int)\n",
    "    A1d = np.ravel(A)\n",
    "    mean = np.mean(A1d)\n",
    "    #Remove DC term (mean), advice from\n",
    "    #http://www.intelligentmining.com/2011/08/08/intro-to-matrix-factorization/\n",
    "    A = A-mean\n",
    "    K = approx\n",
    "    R = itr = iterations\n",
    "    l = learning_rate\n",
    "    b = regularization_rate\n",
    "    N = A.shape[0]\n",
    "    M = A.shape[1]\n",
    "    U = np.random.randn(N,K)\n",
    "    V = np.random.randn(K,M)\n",
    "    print \"Running PMF with:\"\n",
    "    print \"learning rate=\" + `l`\n",
    "    print \"regularization rate=\" + `b`\n",
    "    print \"approximation rank=\" + `K`\n",
    "    print \"iterations=\" + `R`\n",
    "    print \"\"\n",
    "    #PMF using gradient descent as per paper\n",
    "    #Probabilistic Matrix Factorization\n",
    "    #R. Salakhutdinov, A. Minh\n",
    "    for r in range(R):\n",
    "        for i in range(N):\n",
    "            for j in range(M):\n",
    "                if Z[i,j] > 0:\n",
    "                    e = A[i,j] - np.dot(U[i,:],V[:,j])\n",
    "                    U[i,:] = U[i,:] + l*(e*V[:,j] - b*U[i,:])\n",
    "                    V[:,j] = V[:,j] + l*(e*U[i,:] - b*V[:,j])\n",
    "    A_ = np.dot(U,V)\n",
    "    return A_\n",
    "\n",
    "def KPMF(input_matrix, approx=50, iterations=30, learning_rate=.001, adjacency_width=5, adjacency_strength=.5):\n",
    "    A = input_matrix\n",
    "    Z = np.asarray(A > 0,dtype=np.int)\n",
    "    A1d = np.ravel(A)\n",
    "    mean = np.mean(A1d)\n",
    "    A = A-mean\n",
    "    K = approx\n",
    "    R = itr = iterations\n",
    "    l = learning_rate\n",
    "    N = A.shape[0]\n",
    "    M = A.shape[1]\n",
    "    U = np.random.randn(N,K)\n",
    "    V = np.random.randn(K,M)\n",
    "    #KPMF using gradient descent as per paper\n",
    "    #Kernelized Probabilistic Matrix Factorization: Exploiting Graphs and Side Information\n",
    "    #T. Zhou, H. Shan, A. Banerjee, G. Sapiro\n",
    "    #Using diffusion kernel\n",
    "    #U are the rows, we use an adjacency matrix CU to reprent connectivity\n",
    "    #This matrix connects rows +-adjacency_width\n",
    "    #V are the columns, connected columns are CV\n",
    "    #Operate on graph laplacian L, which is the degree matrix D - C\n",
    "    #Applying the diffusion kernel to L, this forms a spatial smoothness graph\n",
    "    bw = adjacency_width\n",
    "    #Use scipy.sparse.diags to generate band matrix with bandwidth = 2*adjacency_width+1\n",
    "    #Example of adjacency_width = 1, N = 4\n",
    "    #[1 1 0 0]\n",
    "    #[1 1 1 0]\n",
    "    #[0 1 1 1]\n",
    "    #[0 0 1 1]\n",
    "    print \"Running KPMF with:\"\n",
    "    print \"learning rate=\" + `l`\n",
    "    print \"bandwidth=\" + `bw`\n",
    "    print \"beta=\" + `b`\n",
    "    print \"approximation rank=\" + `K`\n",
    "    print \"iterations=\" + `R`\n",
    "    print \"\"\n",
    "    CU = sp.diags([1]*(2*bw+1),range(-bw,bw+1),shape=(N,N)).todense()\n",
    "    DU = np.diagflat(np.sum(CU,1))\n",
    "    CV = sp.diags([1]*(2*bw+1),range(-bw,bw+1),shape=(M,M)).todense()\n",
    "    DV = np.diagflat(np.sum(CV,1))\n",
    "    LU = DU - CU\n",
    "    LV = DV - CV\n",
    "    beta = adjacency_strength\n",
    "    KU = sl.expm(beta*LU)\n",
    "    KV = sl.expm(beta*LV)\n",
    "    SU = np.linalg.pinv(KU)\n",
    "    SV = np.linalg.pinv(KV)\n",
    "    for r in range(R):\n",
    "        for i in range(N):\n",
    "            for j in range(M):\n",
    "                if Z[i,j] > 0:\n",
    "                    e = A[i,j] - np.dot(U[i,:],V[:,j])\n",
    "                    U[i,:] = U[i,:] + l*(e*V[:,j] - np.dot(SU[i,:],U))\n",
    "                    V[:,j] = V[:,j] + l*(e*U[i,:] - np.dot(V,SV[:,j]))\n",
    "    A_ = np.dot(U,V)\n",
    "    return A_+mean\n",
    "\n",
    "def get_RMSE(A,A_):\n",
    "    A1d = np.ravel(A)\n",
    "    A_1d = np.ravel(A_)\n",
    "    e = np.mean((A1d-A_1d)**2)\n",
    "    return np.sqrt(e)\n",
    "\n",
    "def combine(A,A_):\n",
    "    out = np.zeros(A.shape)\n",
    "    N = A.shape[0]\n",
    "    M = A.shape[1]\n",
    "    for i in xrange(N):\n",
    "        for j in xrange(M):\n",
    "            if A[i,j] == 0:\n",
    "                out[i,j] = A_[i,j]\n",
    "            else:\n",
    "                out[i,j] = A[i,j]\n",
    "    return out\n",
    "\n",
    "#Rework of lena example\n",
    "#from https://gist.github.com/thearn/5424219\n",
    "#Sparse lena\n",
    "A = np.asarray(lena(),dtype=np.double)\n",
    "plot.figure()\n",
    "plot.title(\"Original Lena\")\n",
    "plot.imshow(A, cmap=cm.gray)\n",
    "plot.savefig(\"pristine_lena.png\")\n",
    "\n",
    "#Full matrix SVD, low rank approximation\n",
    "approx = K = 10\n",
    "iterations = I = 7\n",
    "origA = lena()\n",
    "A_= lowrank_SVD(A,approx=K)\n",
    "plot.figure()\n",
    "RMSE = get_RMSE(origA,A_)\n",
    "plot.title(\"Low Rank SVD (full matrix)\\nRMSE=\" + `RMSE`)\n",
    "plot.imshow(A_, cmap=cm.gray)\n",
    "plot.savefig(\"SVD_full_approx_\"+`K`+\".png\")\n",
    "plot.figure()\n",
    "plot.title(\"Combined Low Rank SVD (full matrix)\\nRMSE=\" + `RMSE`)\n",
    "plot.imshow(combine(A,A_), cmap=cm.gray)\n",
    "plot.savefig(\"CombinedSVD_full_approx_\"+`K`+\".png\")\n",
    "\n",
    "#Make lena sparse matrix setup, sparseness is the percentage of deleted pixels\n",
    "sparseness = .75\n",
    "A = lena()\n",
    "for i in xrange(A.shape[0]):\n",
    "    for j in xrange(A.shape[1]):\n",
    "        if np.random.rand() < sparseness:\n",
    "            A[i,j] = 0.\n",
    "\n",
    "#Sparse lena\n",
    "plot.figure()\n",
    "plot.title(\"Sparse Lena\")\n",
    "plot.imshow(A, cmap=cm.gray)\n",
    "plot.savefig(\"sparse_lena_s_\"+`sparseness`+\".png\")\n",
    "\n",
    "#Sparse matrix, regular SVD example, low rank approximation\n",
    "A_=lowrank_SVD(A,approx=K)\n",
    "plot.figure()\n",
    "RMSE = get_RMSE(origA,A_)\n",
    "plot.title(\"Low Rank SVD\\nRMSE=\"+`RMSE`)\n",
    "plot.imshow(A_, cmap=cm.gray)\n",
    "plot.savefig(\"SVD_sparse_approx_\"+`K`+\".png\")\n",
    "plot.figure()\n",
    "plot.title(\"Combined Low Rank SVD\\nRMSE=\"+`RMSE`)\n",
    "plot.imshow(combine(A,A_), cmap=cm.gray)\n",
    "plot.savefig(\"CombinedSVD_sparse_approx_\"+`K`+\".png\")\n",
    "\n",
    "#Keeping learning rate constant for all PMF examples\n",
    "l = 0.001\n",
    "#Sparse matrix, gradient descent example\n",
    "#Save RMSE as tuple of two values, (b,RMSE)\n",
    "PMF_RMSE=[]\n",
    "for b in [0.,.25,.5,.75,1.]:\n",
    "    A_=PMF(A,approx=K,iterations=I,regularization_rate=b,learning_rate=l)\n",
    "    plot.figure()\n",
    "    RMSE = get_RMSE(origA,A_)\n",
    "    PMF_RMSE.append((b,RMSE))\n",
    "    #Lambda is the regularization rate (lambda_v = lambda_u from the paper\n",
    "    plot.title(\"PMF, $\\lambda$=\" + `b` + \"\\nRMSE=\" + `RMSE`)\n",
    "    plot.imshow(A_, cmap=cm.gray)\n",
    "    plot.savefig(\"PMF_b_\"+`int(10*b)`+\".png\")\n",
    "    plot.figure()\n",
    "    plot.title(\"Combined PMF, $\\lambda$=\" + `b` + \"\\nRMSE=\" + `RMSE`)\n",
    "    plot.imshow(combine(A,A_), cmap=cm.gray)\n",
    "    plot.savefig(\"CombinedPMF_b_\"+`int(10*b)`+\".png\")\n",
    "\n",
    "#Sparse matrix, kernelized probabilistic matrix\n",
    "#Save RMSE as tuple of 3 values (b,w,RMSE)\n",
    "KPMF_RMSE=[]\n",
    "for w in [0,4,10,20,40]:\n",
    "    blist = []\n",
    "    for b in [0.,.25,.5,.75,1.]:\n",
    "        A_=KPMF(A,approx=K,iterations=I,adjacency_width=w,adjacency_strength=b,learning_rate=l)\n",
    "        plot.figure()\n",
    "        RMSE = get_RMSE(origA,A_)\n",
    "        blist.append(RMSE)\n",
    "        plot.title(r\"Kernelized PMF, $\\beta$=\" + `b` + \", width=\" + `w`+ \"\\nRMSE=\" + `RMSE`)\n",
    "        plot.imshow(A_, cmap=cm.gray)\n",
    "        plot.savefig(\"KPMF_w\"+`w`+\"_b_\"+`int(10*b)`+\".png\")\n",
    "        plot.figure()\n",
    "        plot.title(r\"Combined KPMF, $\\beta$=\" + `b` + \", width=\" + `w`+ \"\\nRMSE=\" + `RMSE`)\n",
    "        plot.imshow(combine(A,A_), cmap=cm.gray)\n",
    "        plot.savefig(\"CombinedKPMF_w\"+`w`+\"_b_\"+`int(10*b)`+\".png\")\n",
    "    KPMF_RMSE.append((w,tuple(blist)))\n",
    "\n",
    "colors=['r','b','g','c','m','k']\n",
    "plot.figure()\n",
    "bs,RMSEs = zip(*PMF_RMSE)\n",
    "ws,bRMSEs = zip(*KPMF_RMSE)\n",
    "labels=[\"PMF\"]+[\"KPMF_\"+`w` for w in ws]\n",
    "plot.title(\"RMSE vs. regularization/diffusion rate\")\n",
    "for err,col,lbl in zip((RMSEs,)+bRMSEs,colors,labels):\n",
    "    plot.plot(bs, err, col, label=str(lbl))\n",
    "plot.xlabel('Regularization rate')\n",
    "plot.ylabel('RMSE')\n",
    "plot.legend()\n",
    "plot.savefig(\"reg_rate_and_diffusion_RMSE.png\")\n",
    "\n",
    "plot.figure()\n",
    "plot.title(\"Average RMSE vs. kernel bandwidth\")\n",
    "for err, col, lbl in zip(bRMSEs,\n",
    "                         colors,\n",
    "                         bs):\n",
    "    plot.plot(ws, err, col, label=str(lbl))\n",
    "plot.xlabel('Kernel bandwidth')\n",
    "plot.ylabel('Average RMSE over calculated rates')\n",
    "plot.legend()\n",
    "plot.savefig(\"kernel_width_mean_RMSE.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Partie 1 : Données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Partie 2.1 : Spécification du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def KPMF(input_matrix, approx=50, iterations=30, learning_rate=.001, adjacency_width=5, adjacency_strength=.5):\n",
    "    A = input_matrix\n",
    "    Z = np.asarray(A > 0,dtype=np.int)\n",
    "    A1d = np.ravel(A)\n",
    "    mean = np.mean(A1d)\n",
    "    A = A-mean\n",
    "    K = approx\n",
    "    R = itr = iterations\n",
    "    l = learning_rate\n",
    "    N = A.shape[0]\n",
    "    M = A.shape[1]\n",
    "    U = np.random.randn(N,K)\n",
    "    V = np.random.randn(K,M)\n",
    "    #KPMF using gradient descent as per paper\n",
    "    #Kernelized Probabilistic Matrix Factorization: Exploiting Graphs and Side Information\n",
    "    #T. Zhou, H. Shan, A. Banerjee, G. Sapiro\n",
    "    #Using diffusion kernel\n",
    "    #U are the rows, we use an adjacency matrix CU to reprent connectivity\n",
    "    #This matrix connects rows +-adjacency_width\n",
    "    #V are the columns, connected columns are CV\n",
    "    #Operate on graph laplacian L, which is the degree matrix D - C\n",
    "    #Applying the diffusion kernel to L, this forms a spatial smoothness graph\n",
    "    bw = adjacency_width\n",
    "    #Use scipy.sparse.diags to generate band matrix with bandwidth = 2*adjacency_width+1\n",
    "    #Example of adjacency_width = 1, N = 4\n",
    "    #[1 1 0 0]\n",
    "    #[1 1 1 0]\n",
    "    #[0 1 1 1]\n",
    "    #[0 0 1 1]\n",
    "    print \"Running KPMF with:\"\n",
    "    print \"learning rate=\" + `l`\n",
    "    print \"bandwidth=\" + `bw`\n",
    "    print \"beta=\" + `b`\n",
    "    print \"approximation rank=\" + `K`\n",
    "    print \"iterations=\" + `R`\n",
    "    print \"\"\n",
    "    CU = sp.diags([1]*(2*bw+1),range(-bw,bw+1),shape=(N,N)).todense()\n",
    "    DU = np.diagflat(np.sum(CU,1))\n",
    "    CV = sp.diags([1]*(2*bw+1),range(-bw,bw+1),shape=(M,M)).todense()\n",
    "    DV = np.diagflat(np.sum(CV,1))\n",
    "    LU = DU - CU\n",
    "    LV = DV - CV\n",
    "    beta = adjacency_strength\n",
    "    KU = sl.expm(beta*LU)\n",
    "    KV = sl.expm(beta*LV)\n",
    "    SU = np.linalg.pinv(KU)\n",
    "    SV = np.linalg.pinv(KV)\n",
    "    for r in range(R):\n",
    "        for i in range(N):\n",
    "            for j in range(M):\n",
    "                if Z[i,j] > 0:\n",
    "                    e = A[i,j] - np.dot(U[i,:],V[:,j])\n",
    "                    U[i,:] = U[i,:] + l*(e*V[:,j] - np.dot(SU[i,:],U))\n",
    "                    V[:,j] = V[:,j] + l*(e*U[i,:] - np.dot(V,SV[:,j]))\n",
    "    A_ = np.dot(U,V)\n",
    "    return A_+mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def KPMF(input_matrix, approx=50, iterations=30, learning_rate=.001, adjacency_width=5, adjacency_strength=.5):\n",
    "    \n",
    "    # Hyperparamètres\n",
    "    R = itr = iterations\n",
    "    l = learning_rate\n",
    "    K = approx # Rang !!! (changer les termes pour uniformité)\n",
    "    \n",
    "    # Initialisation des paramètres\n",
    "    A = input_matrix # Matrice de données\n",
    "    Z = np.asarray(A > 0) # Matrices des éléments absents\n",
    "    \n",
    "    # Enlever la moyenne ?? Pourquoi??\n",
    "    A1d = np.ravel(A)\n",
    "    mean = np.mean(A1d)\n",
    "    A = A - mean\n",
    "    \n",
    "    # Matrices latentes\n",
    "    N = A.shape[0] # Nombre de lignes dans A\n",
    "    M = A.shape[1] # Nombre de colones dans A\n",
    "    U = np.random.randn(N, K) # Initialisation de U\n",
    "    V = np.random.randn(K, M) # Initialisation de V\n",
    "    \n",
    "    \n",
    "    #KPMF using gradient descent as per paper\n",
    "        # Préparation de la descente du gradient\n",
    "    \n",
    "        #Using diffusion kernel\n",
    "            #U are the rows, we use an adjacency matrix CU to reprent connectivity\n",
    "            #This matrix connects rows +-adjacency_width\n",
    "            #V are the columns, connected columns are CV\n",
    "            #Operate on graph laplacian L, which is the degree matrix D - C\n",
    "            #Applying the diffusion kernel to L, this forms a spatial smoothness graph\n",
    "    bw = adjacency_width\n",
    "    print(\"BW\")\n",
    "            #Use scipy.sparse.diags to generate band matrix with bandwidth = 2*adjacency_width+1\n",
    "            #Example of adjacency_width = 1, N = 4\n",
    "            #[1 1 0 0]\n",
    "            #[1 1 1 0]\n",
    "            #[0 1 1 1]\n",
    "            #[0 0 1 1]\n",
    "\n",
    "    # Matrice adjacente pour U\n",
    "    CU = sp.diags([1] * (2 * bw + 1),\n",
    "                  range(-bw, bw + 1),\n",
    "                  shape=(N, N)).todense()\n",
    "    \n",
    "    DU = np.diagflat(np.sum(CU, 1))\n",
    "    \n",
    "    # Matrice adjacente pour V\n",
    "    CV = sp.diags([1] * (2 * bw + 1),\n",
    "                  range(-bw, bw + 1),\n",
    "                  shape=(M, M)).todense()\n",
    "    \n",
    "    DV = np.diagflat(np.sum(CV, 1)) ## Tout les 1 sur les lignes sont sommés sur la diago (?)\n",
    "    print(\"CU, CV\")\n",
    "    # Commprendre le calcul, pourquo ila différence??\n",
    "    LU = DU - CU \n",
    "    \n",
    "    LV = DV - CV\n",
    "    print(\"LU, LV\")\n",
    "    beta = adjacency_strength\n",
    "    \n",
    "    # Changement de sl.expm pour plus de vitesse\n",
    "    # https://github.com/simone-viozzi/matrix_exponentiation\n",
    "    # https://docs.scipy.org/doc/scipy/reference/generated/scipy.linalg.expm.html\n",
    "    #KU = sl.expm(beta * LU)\n",
    "    #print(KU)\n",
    "    b_KU = beta * LU\n",
    "    KU = np.cos(b_KU) + np.sin(b_KU)\n",
    "    #print(KU2)\n",
    "    #KU == KU2\n",
    "    \n",
    "    \n",
    "    print(\"KU\")\n",
    "    #KV = sl.expm(beta * LV)\n",
    "    b_LV = beta * LV\n",
    "    KV = np.cos(b_LV) + np.sin(b_LV)\n",
    "    print(\"KV\")\n",
    "    \n",
    "    # De manière codée à main\n",
    "    #KU = beta * LU\n",
    "    #eigvalue, eigvectors = np.linalg.eig(KU)\n",
    "    #e_Lambda = np.eye(np.size(KU, 0))*(np.exp(eigvalue))\n",
    "    #KU = eigvectors*e_Lambda*eigvectors.I\n",
    "    #print(KU.shape)\n",
    "    #print(KU)\n",
    "    #print(\"KU\")\n",
    "    #KV = beta * LV\n",
    "    #eigvalue, eigvectors = np.linalg.eig(KV)\n",
    "    #e_Lambda = np.eye(np.size(KV, 0))*(np.exp(eigvalue))\n",
    "    #KV = eigvectors*e_Lambda*eigvectors.I\n",
    "    #print(KV.shape)\n",
    "  #  print(KV)\n",
    " #   print(\"KV\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    SU = np.linalg.pinv(KU)\n",
    "    print(\"SU\")\n",
    "    SV = np.linalg.pinv(KV)\n",
    "    print(SV)\n",
    "    print(\"SV\")\n",
    "    print(V)\n",
    "    \n",
    "    # Informations pour l'utilisateurs lors (grid search)\n",
    "    print(\"\")\n",
    "    print(\"Running KPMF with:\")\n",
    "    print(\"  LR = {}\".format(l))\n",
    "    print(\"  Bandwidth = {}\".format(bw))\n",
    "    print(\"  beta = {}\".format(b))\n",
    "    print(\"  Rank = {}\".format(K))\n",
    "    print(\"  Iterations maximum = {}\".format(R))\n",
    "    print(\"\")\n",
    "    \n",
    "    # Roulement de la descente du gradient\n",
    "    for r in range(R):\n",
    "        for i in range(N):\n",
    "            for j in range(M):\n",
    "                if Z[i, j] > 0:\n",
    "                    print(\"e\")\n",
    "                    e = A[i, j] - np.dot(U[i, :], V[:, j])\n",
    "                    print(\"U\")\n",
    "                    U[i, :] = U[i, :] + l * (e * V[:, j] - \n",
    "                                             np.dot(SU[i, :], U))\n",
    "                    print(\"V\")\n",
    "                    V[:, j] = V[:, j] + l * (e * U[i, :] - \n",
    "                                             np.dot(V, SV[:, j]))\n",
    "    A_ = np.dot(U, V)\n",
    "    return A_ + mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-05T03:34:27.677285Z",
     "start_time": "2020-06-05T03:34:27.178252Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def KPMF(input_matrix, approx=50, iterations=30, learning_rate=.001, adjacency_width=5, adjacency_strength=.5):\n",
    "    \n",
    "    # Hyperparamètres\n",
    "    R = itr = iterations\n",
    "    l = learning_rate\n",
    "    K = approx # Rang !!! (changer les termes pour uniformité)\n",
    "    \n",
    "    # Initialisation des paramètres\n",
    "    A = input_matrix # Matrice de données\n",
    "    Z = np.asarray(A > 0) # Matrices des éléments absents\n",
    "    \n",
    "    # Enlever la moyenne ?? Pourquoi??\n",
    "    A1d = np.ravel(A)\n",
    "    mean = np.mean(A1d)\n",
    "    A = A - mean\n",
    "    \n",
    "    # Matrices latentes\n",
    "    N = A.shape[0] # Nombre de lignes dans A\n",
    "    M = A.shape[1] # Nombre de colones dans A\n",
    "    U = np.random.randn(N, K) # Initialisation de U\n",
    "    V = np.random.randn(K, M) # Initialisation de V\n",
    "    \n",
    "    \n",
    "    #KPMF using gradient descent as per paper\n",
    "        # Préparation de la descente du gradient\n",
    "    \n",
    "        #Using diffusion kernel\n",
    "            #U are the rows, we use an adjacency matrix CU to reprent connectivity\n",
    "            #This matrix connects rows +-adjacency_width\n",
    "            #V are the columns, connected columns are CV\n",
    "            #Operate on graph laplacian L, which is the degree matrix D - C\n",
    "            #Applying the diffusion kernel to L, this forms a spatial smoothness graph\n",
    "    bw = adjacency_width\n",
    "    print(\"BW\")\n",
    "            #Use scipy.sparse.diags to generate band matrix with bandwidth = 2*adjacency_width+1\n",
    "            #Example of adjacency_width = 1, N = 4\n",
    "            #[1 1 0 0]\n",
    "            #[1 1 1 0]\n",
    "            #[0 1 1 1]\n",
    "            #[0 0 1 1]\n",
    "\n",
    "    # Matrice adjacente pour U\n",
    "    CU = sp.diags([1] * (2 * bw + 1),\n",
    "                  range(-bw, bw + 1),\n",
    "                  shape=(N, N)).todense()\n",
    "    \n",
    "    DU = np.diagflat(np.sum(CU, 1))\n",
    "    \n",
    "    # Matrice adjacente pour V\n",
    "    CV = sp.diags([1] * (2 * bw + 1),\n",
    "                  range(-bw, bw + 1),\n",
    "                  shape=(M, M)).todense()\n",
    "    \n",
    "    DV = np.diagflat(np.sum(CV, 1)) ## Tout les 1 sur les lignes sont sommés sur la diago (?)\n",
    "    print(\"CU, CV\")\n",
    "    # Commprendre le calcul, pourquo ila différence??\n",
    "    LU = DU - CU \n",
    "    \n",
    "    LV = DV - CV\n",
    "    print(\"LU, LV\")\n",
    "    beta = adjacency_strength\n",
    "    \n",
    "    # Changement de sl.expm pour plus de vitesse\n",
    "    # https://github.com/simone-viozzi/matrix_exponentiation\n",
    "    # https://docs.scipy.org/doc/scipy/reference/generated/scipy.linalg.expm.html\n",
    "    #KU = sl.expm(beta * LU)\n",
    "    #print(KU)\n",
    "    b_KU = beta * LU\n",
    "    KU = np.cos(b_KU) + np.sin(b_KU)\n",
    "    #print(KU2)\n",
    "    #KU == KU2\n",
    "    \n",
    "    \n",
    "    print(\"KU\")\n",
    "    #KV = sl.expm(beta * LV)\n",
    "    b_LV = beta * LV\n",
    "    KV = np.cos(b_LV) + np.sin(b_LV)\n",
    "    print(\"KV\")\n",
    "    \n",
    "    # De manière codée à main\n",
    "    #KU = beta * LU\n",
    "    #eigvalue, eigvectors = np.linalg.eig(KU)\n",
    "    #e_Lambda = np.eye(np.size(KU, 0))*(np.exp(eigvalue))\n",
    "    #KU = eigvectors*e_Lambda*eigvectors.I\n",
    "    #print(KU.shape)\n",
    "    #print(KU)\n",
    "    #print(\"KU\")\n",
    "    #KV = beta * LV\n",
    "    #eigvalue, eigvectors = np.linalg.eig(KV)\n",
    "    #e_Lambda = np.eye(np.size(KV, 0))*(np.exp(eigvalue))\n",
    "    #KV = eigvectors*e_Lambda*eigvectors.I\n",
    "    #print(KV.shape)\n",
    "  #  print(KV)\n",
    " #   print(\"KV\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    SU = np.linalg.pinv(KU)\n",
    "    print(\"SU\")\n",
    "    SV = np.linalg.pinv(KV)\n",
    "    print(SV)\n",
    "    print(\"SV\")\n",
    "    print(V)\n",
    "    \n",
    "    # Informations pour l'utilisateurs lors (grid search)\n",
    "    print(\"\")\n",
    "    print(\"Running KPMF with:\")\n",
    "    print(\"  LR = {}\".format(l))\n",
    "    print(\"  Bandwidth = {}\".format(bw))\n",
    "    print(\"  beta = {}\".format(b))\n",
    "    print(\"  Rank = {}\".format(K))\n",
    "    print(\"  Iterations maximum = {}\".format(R))\n",
    "    print(\"\")\n",
    "    \n",
    "    # Roulement de la descente du gradient\n",
    "    for r in range(R):\n",
    "        for i in range(N):\n",
    "            for j in range(M):\n",
    "                if Z[i, j] > 0:\n",
    "                    print(\"e\")\n",
    "                    e = A[i, j] - np.dot(U[i, :], V[:, j])\n",
    "                    print(\"U\")\n",
    "                    U[i, :] = U[i, :] + l * (e * V[:, j] - \n",
    "                                             np.dot(SU[i, :], U))\n",
    "                    print(\"V\")\n",
    "                    V[:, j] = V[:, j] + l * (e * U[i, :] - \n",
    "                                             np.dot(V, SV[:, j]))\n",
    "    A_ = np.dot(U, V)\n",
    "    return A_ + mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-05T19:13:31.772750Z",
     "start_time": "2020-06-05T19:13:21.279Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def get_RMSE(A, A_):\n",
    "    A1d = np.ravel(A)\n",
    "    A_1d = np.ravel(A_)\n",
    "    e = np.mean((A1d - A_1d) ** 2)\n",
    "    return np.sqrt(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-05T19:13:31.772750Z",
     "start_time": "2020-06-05T19:13:21.754Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def combine(A, A_):\n",
    "    out = np.zeros(A.shape)\n",
    "    N = A.shape[0]\n",
    "    M = A.shape[1]\n",
    "    for i in range(N):\n",
    "        for j in range(M):\n",
    "            if A[i, j] == 0:\n",
    "                out[i, j] = A_[i, j]\n",
    "            else:\n",
    "                out[i, j] = A[i, j]\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Rework of lena example\n",
    "#from https://gist.github.com/thearn/5424219\n",
    "#Sparse lena\n",
    "\n",
    "\n",
    "#Sparse matrix, regular SVD example, low rank approximation\n",
    "A_=lowrank_SVD(A,approx=K)\n",
    "\n",
    "\n",
    "#Keeping learning rate constant for all PMF examples\n",
    "l = 0.001\n",
    "#Sparse matrix, gradient descent example\n",
    "#Save RMSE as tuple of two values, (b,RMSE)\n",
    "PMF_RMSE=[]\n",
    "b = 0. # [0.,.25,.5,.75,1.]\n",
    "A_=PMF(A,approx=K,iterations=I,regularization_rate=b,learning_rate=l)\n",
    "RMSE = get_RMSE(origA,A_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Sparse matrix, kernelized probabilistic matrix\n",
    "#Save RMSE as tuple of 3 values (b,w,RMSE)\n",
    "KPMF_RMSE=[]\n",
    "w = 0 # [0,4,10,20,40]\n",
    "b = 0.\n",
    "A_ = KPMF(A,approx=K,iterations=I,adjacency_width=w,adjacency_strength=b,learning_rate=l)\n",
    "RMSE = get_RMSE(origA, A_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "A = np.asarray(lena(),dtype=np.double)\n",
    "#Full matrix SVD, low rank approximation\n",
    "approx = K = 10\n",
    "iterations = I = 7\n",
    "origA = lena()\n",
    "A_ = lowrank_SVD(A,approx=K)\n",
    "RMSE = get_RMSE(origA,A_)\n",
    "\n",
    "#Make lena sparse matrix setup, sparseness is the percentage of deleted pixels\n",
    "sparseness = .75\n",
    "A = lena()\n",
    "for i in xrange(A.shape[0]):\n",
    "    for j in xrange(A.shape[1]):\n",
    "        if np.random.rand() < sparseness:\n",
    "            A[i,j] = 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Graph kernel\n",
    "\n",
    "\n",
    "#KPMF using gradient descent as per paper\n",
    "        # Préparation de la descente du gradient\n",
    "    \n",
    "        #Using diffusion kernel\n",
    "            #U are the rows, we use an adjacency matrix CU to reprent connectivity\n",
    "            #This matrix connects rows +-adjacency_width\n",
    "            #V are the columns, connected columns are CV\n",
    "            #Operate on graph laplacian L, which is the degree matrix D - C\n",
    "            #Applying the diffusion kernel to L, this forms a spatial smoothness graph\n",
    "bw = adjacency_width\n",
    "print(\"BW\")\n",
    "            #Use scipy.sparse.diags to generate band matrix with bandwidth = 2*adjacency_width+1\n",
    "            #Example of adjacency_width = 1, N = 4\n",
    "            #[1 1 0 0]\n",
    "            #[1 1 1 0]\n",
    "            #[0 1 1 1]\n",
    "            #[0 0 1 1]\n",
    "\n",
    "# Matrice adjacente pour U\n",
    "    CU = sp.diags([1] * (2 * bw + 1),\n",
    "                  range(-bw, bw + 1),\n",
    "                  shape=(N, N)).todense()\n",
    "    \n",
    "    DU = np.diagflat(np.sum(CU, 1))\n",
    "    \n",
    "    # Matrice adjacente pour V\n",
    "    CV = sp.diags([1] * (2 * bw + 1),\n",
    "                  range(-bw, bw + 1),\n",
    "                  shape=(M, M)).todense()\n",
    "    \n",
    "    DV = np.diagflat(np.sum(CV, 1)) ## Tout les 1 sur les lignes sont sommés sur la diago (?)\n",
    "    print(\"CU, CV\")\n",
    "    # Commprendre le calcul, pourquo ila différence??\n",
    "    LU = DU - CU \n",
    "    \n",
    "    LV = DV - CV\n",
    "    print(\"LU, LV\")\n",
    "    beta = adjacency_strength\n",
    "    \n",
    "    # Changement de sl.expm pour plus de vitesse\n",
    "    # https://github.com/simone-viozzi/matrix_exponentiation\n",
    "    # https://docs.scipy.org/doc/scipy/reference/generated/scipy.linalg.expm.html\n",
    "    #KU = sl.expm(beta * LU)\n",
    "    #print(KU)\n",
    "    b_KU = beta * LU\n",
    "    KU = np.cos(b_KU) + np.sin(b_KU)\n",
    "    #print(KU2)\n",
    "    #KU == KU2\n",
    "    \n",
    "    \n",
    "    print(\"KU\")\n",
    "    #KV = sl.expm(beta * LV)\n",
    "    b_LV = beta * LV\n",
    "    KV = np.cos(b_LV) + np.sin(b_LV)\n",
    "    print(\"KV\")\n",
    "    \n",
    "    # De manière codée à main\n",
    "    #KU = beta * LU\n",
    "    #eigvalue, eigvectors = np.linalg.eig(KU)\n",
    "    #e_Lambda = np.eye(np.size(KU, 0))*(np.exp(eigvalue))\n",
    "    #KU = eigvectors*e_Lambda*eigvectors.I\n",
    "    #print(KU.shape)\n",
    "    #print(KU)\n",
    "    #print(\"KU\")\n",
    "    #KV = beta * LV\n",
    "    #eigvalue, eigvectors = np.linalg.eig(KV)\n",
    "    #e_Lambda = np.eye(np.size(KV, 0))*(np.exp(eigvalue))\n",
    "    #KV = eigvectors*e_Lambda*eigvectors.I\n",
    "    #print(KV.shape)\n",
    "  #  print(KV)\n",
    " #   print(\"KV\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    SU = np.linalg.pinv(KU)\n",
    "    print(\"SU\")\n",
    "    SV = np.linalg.pinv(KV)\n",
    "    print(SV)\n",
    "    print(\"SV\")\n",
    "    print(V)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "hidden": true
   },
   "source": [
    "bw = 5 # adjacency_width\n",
    "# band matrix with bandwidth = 2*adjacency_width+1\n",
    "CU = sp.diags([1] * (2 * bw + 1),\n",
    "              range(-bw, bw + 1),\n",
    "              shape=(N, N)).todense()\n",
    "#print(CU)\n",
    "\n",
    "# Matrice de degrés\n",
    "DU = np.diagflat(np.sum(CU, 1))\n",
    "#print(DU)\n",
    "\n",
    "LU = DU - CU # Graph laplacian\n",
    "#print(LU)\n",
    "\n",
    "beta = 0.1 # adjacency_strength\n",
    "KU = beta * LU\n",
    "#print(\"KU\")\n",
    "#print(KU)\n",
    "KU = np.cos(KU) + np.sin(KU) #(pourquoi le met-il en exponentiel?)\n",
    "#print(\"KU\")\n",
    "#print(KU)\n",
    "KU_inv = np.linalg.pinv(KU)\n",
    "#print(\"KU_INV\")\n",
    "#print(KU_inv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Partie 2 : Modèle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-05T21:52:48.868514Z",
     "start_time": "2020-06-05T21:52:48.697826Z"
    }
   },
   "outputs": [],
   "source": [
    "# Téléchargement des données\n",
    "import scipy.io\n",
    "from tensorly import unfold\n",
    "tensor = scipy.io.loadmat('data/Guangzhou-data-set/tensor.mat')\n",
    "tensor = tensor['tensor']\n",
    "random_matrix = scipy.io.loadmat('data/Guangzhou-data-set/random_matrix.mat')\n",
    "random_matrix = random_matrix['random_matrix']\n",
    "random_tensor = scipy.io.loadmat('data/Guangzhou-data-set/random_tensor.mat')\n",
    "random_tensor = random_tensor['random_tensor']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-05T21:52:49.078270Z",
     "start_time": "2020-06-05T21:52:49.074294Z"
    }
   },
   "outputs": [],
   "source": [
    "tensor = tensor[:50, :5, :] # diminuer la dimension du renseur pour avoir quelque chose de rapide\n",
    "\n",
    "# faire idem sur la matrice random\n",
    "random_matrix = random_matrix[:50, :5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-05T21:52:49.420356Z",
     "start_time": "2020-06-05T21:52:49.416403Z"
    }
   },
   "outputs": [],
   "source": [
    "# Initialisation de la matrice pleine\n",
    "\n",
    "dense_mat = tensor.reshape([tensor.shape[0], tensor.shape[1] * tensor.shape[2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-05T21:58:34.795924Z",
     "start_time": "2020-06-05T21:58:34.791933Z"
    }
   },
   "outputs": [],
   "source": [
    "# Initialisation de la matrice avec valeurs manquantes\n",
    "missing_rate = 0.4\n",
    "\n",
    "# =============================================================================\n",
    "### Random missing (RM) scenario\n",
    "### Set the RM scenario by:\n",
    "# binary_mat = (np.round(random_tensor + 0.5 - missing_rate)\n",
    "#               .reshape([random_tensor.shape[0], random_tensor.shape[1] * random_tensor.shape[2]]))\n",
    "# =============================================================================\n",
    "\n",
    "# ============================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-05T21:58:35.116068Z",
     "start_time": "2020-06-05T21:58:35.108089Z"
    }
   },
   "outputs": [],
   "source": [
    "### Non-random missing (NM) scenario\n",
    "### Set the NM scenario by:\n",
    "\n",
    "binary_tensor = np.zeros(tensor.shape)\n",
    "for i1 in range(tensor.shape[0]):\n",
    "    for i2 in range(tensor.shape[1]):\n",
    "        binary_tensor[i1, i2, :] = np.round(random_matrix[i1, i2] + 0.5 - missing_rate)\n",
    "binary_mat = binary_tensor.reshape([binary_tensor.shape[0], binary_tensor.shape[1] * binary_tensor.shape[2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-05T21:58:35.377369Z",
     "start_time": "2020-06-05T21:58:35.373379Z"
    }
   },
   "outputs": [],
   "source": [
    "sparse_mat = np.multiply(dense_mat, binary_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-05T21:58:54.954177Z",
     "start_time": "2020-06-05T21:58:54.951188Z"
    }
   },
   "outputs": [],
   "source": [
    "A = np.asarray(sparse_mat, dtype = np.float64)\n",
    "origA = np.asarray(dense_mat, dtype = np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-05T23:03:07.053528Z",
     "start_time": "2020-06-05T23:03:07.044539Z"
    }
   },
   "outputs": [],
   "source": [
    "A = np.asarray([[0,2,1,2,4,3,2,0,9,8,7,6,5,4,0],[0,2,1,2,4,3,2,0,9,8,7,6,5,4,0],[0,2,1,2,4,3,2,0,9,8,7,6,5,4,0], [0,2,1,2,4,3,2,0,9,8,7,6,5,4,0], [0,2,1,2,4,3,2,0,9,8,7,6,5,4,0], [0,2,1,2,4,3,2,0,9,8,7,6,5,4,0], [0,2,1,2,4,3,2,0,9,8,7,6,5,4,0] ])\n",
    "origA = np.asarray([[1,2,1,2,4,3,2,1,9,8,7,6,5,4,1], [1,2,1,2,4,3,2,1,9,8,7,6,5,4,1], [1,2,1,2,4,3,2,1,9,8,7,6,5,4,1], [1,2,1,2,4,3,2,1,9,8,7,6,5,4,1], [1,2,1,2,4,3,2,1,9,8,7,6,5,4,1], [1,2,1,2,4,3,2,1,9,8,7,6,5,4,1], [1,2,1,2,4,3,2,1,9,8,7,6,5,4,1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-05T23:03:07.419177Z",
     "start_time": "2020-06-05T23:03:07.415188Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7, 15) 7 15\n"
     ]
    }
   ],
   "source": [
    "# Paramètres\n",
    "N = A.shape[0] # Nombre de lignes dans A\n",
    "M = A.shape[1] # Nombre de colones dans A\n",
    "\n",
    "print(A.shape, N, M)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Création de la matrice de cov (kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-05T23:03:44.774817Z",
     "start_time": "2020-06-05T23:03:44.771792Z"
    }
   },
   "outputs": [],
   "source": [
    "def K_inv(dim, poids):\n",
    "    \"\"\"\n",
    "    dim : Dimension M ou N selon la matrice U ou V à créer un kernel\n",
    "    poids : Poids des éléments sur la diagonal\n",
    "    \n",
    "    from numpy.linalg import inv\n",
    "    KV = 0.2 * np.eye(M, M)\n",
    "    KV_inv = np.linalg.pinv(KV)\n",
    "    KV_inv\n",
    "    \n",
    "    \"\"\"\n",
    "    K = poids * np.eye(dim, dim)\n",
    "    K_inv = np.linalg.pinv(K)\n",
    "    return K_inv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-05T23:03:45.275656Z",
     "start_time": "2020-06-05T23:03:45.269674Z"
    }
   },
   "outputs": [],
   "source": [
    "def graph_kernel(a_width, a_strength, dim):\n",
    "    \"\"\"\n",
    "    Fonction pour créer le kernel des matrices latentes\n",
    "    \n",
    "        - Objectif : Avoir la matrice de covariance pour les lignes et colonnes basée sur le kernel graph (en utilisant\n",
    "                     l'information externe)\n",
    "    \n",
    "    Paramètres en entré :     ** Peuvent être optimisés **\n",
    "        a_width : Adjacency width\n",
    "        a_strength : Adjacency strength\n",
    "        dim : Dimension de U ou V selon la matrice voulue\n",
    "        \n",
    "    Paramètres en sortie : \n",
    "        K_inv : Kernel inverse pour le facteur latent\n",
    "    \n",
    "    \"\"\"\n",
    "    #CU = sp.diags([1]*(2*bw+1),range(-bw,bw+1),shape=(N,N)).todense()\n",
    "    #DU = np.diagflat(np.sum(CU,1))\n",
    "    #CV = sp.diags([1]*(2*bw+1),range(-bw,bw+1),shape=(M,M)).todense()\n",
    "    #DV = np.diagflat(np.sum(CV,1))\n",
    "    #LU = DU - CU\n",
    "    #LV = DV - CV\n",
    "    #beta = adjacency_strength\n",
    "    #KU = sl.expm(beta*LU)\n",
    "    #KV = sl.expm(beta*LV)\n",
    "    #SU = np.linalg.pinv(KU)\n",
    "    #SV = np.linalg.pinv(KV)\n",
    "    # Band matrix with bandwidth = 2 * adjacency_width + 1\n",
    "    C = sp.diags([1] * (2 * a_width + 1),\n",
    "                  range(-a_width, a_width + 1),\n",
    "                  shape=(dim, dim)).todense()\n",
    "    \n",
    "    # Matrice de degrés\n",
    "    D = np.diagflat(np.sum(C, 1))\n",
    "    \n",
    "    # Graph laplacian\n",
    "    L = D - C\n",
    "    \n",
    "    # Importance des poids du graph laplacian\n",
    "    #K = a_strength * L\n",
    "    #K = np.cos(K) + np.sin(K) # expm (exposant !?)\n",
    "    K = sl.expm(a_strength * L)\n",
    "    \n",
    "    # Matrice inverse ou pseudoinverse (selon la possibilité de calcul)\n",
    "    K_inv = np.linalg.pinv(K)\n",
    "    \n",
    "    return K_inv   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-05T23:03:46.015596Z",
     "start_time": "2020-06-05T23:03:46.006588Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6.22441269e-01, 7.08496923e-02, 6.81577073e-02, 6.55491911e-02,\n",
       "        6.30199915e-02, 6.05685813e-02, 1.45377987e-02, 1.17672329e-02,\n",
       "        9.06841787e-03, 6.44114990e-03, 3.98973973e-03, 1.46054004e-03,\n",
       "        1.04185746e-03, 6.92066105e-04, 4.14764771e-04],\n",
       "       [7.08496923e-02, 5.67006110e-01, 6.78163100e-02, 6.52914338e-02,\n",
       "        6.28421767e-02, 6.04688159e-02, 5.77837511e-02, 1.41041114e-02,\n",
       "        1.14211289e-02, 8.80604304e-03, 6.43268221e-03, 3.98342509e-03,\n",
       "        1.46032072e-03, 1.04193261e-03, 6.92066105e-04],\n",
       "       [6.81577073e-02, 6.78163100e-02, 5.16737103e-01, 6.49665571e-02,\n",
       "        6.25969741e-02, 6.03013984e-02, 5.77700417e-02, 5.51725193e-02,\n",
       "        1.36893355e-02, 1.10897716e-02, 8.79419594e-03, 6.42461293e-03,\n",
       "        3.98129523e-03, 1.46032072e-03, 1.04185746e-03],\n",
       "       [6.55491911e-02, 6.52914338e-02, 6.49665571e-02, 4.71147605e-01,\n",
       "        6.22877814e-02, 6.00697398e-02, 5.76883540e-02, 5.52407265e-02,\n",
       "        5.27266636e-02, 1.32965389e-02, 1.10784973e-02, 8.78833309e-03,\n",
       "        6.42461293e-03, 3.98342509e-03, 1.46054004e-03],\n",
       "       [6.30199915e-02, 6.28421767e-02, 6.25969741e-02, 6.22877814e-02,\n",
       "        4.29797165e-01, 5.97769775e-02, 5.75419770e-02, 5.52407265e-02,\n",
       "        5.28730406e-02, 5.04385892e-02, 1.32894854e-02, 1.10784973e-02,\n",
       "        8.79419594e-03, 6.43268221e-03, 3.98973973e-03],\n",
       "       [6.05685813e-02, 6.04688159e-02, 6.03013984e-02, 6.00697398e-02,\n",
       "        5.97769775e-02, 3.92362352e-01, 5.73991267e-02, 5.52407265e-02,\n",
       "        5.30158909e-02, 5.07242981e-02, 5.04385892e-02, 1.32965389e-02,\n",
       "        1.10897716e-02, 8.80604304e-03, 6.44114990e-03],\n",
       "       [1.45377987e-02, 5.77837511e-02, 5.77700417e-02, 5.76883540e-02,\n",
       "        5.75419770e-02, 5.73991267e-02, 3.92099935e-01, 5.72277102e-02,\n",
       "        5.51568286e-02, 5.30158909e-02, 5.28730406e-02, 5.27266636e-02,\n",
       "        1.36893355e-02, 1.14211289e-02, 9.06841787e-03],\n",
       "       [1.17672329e-02, 1.41041114e-02, 5.51725193e-02, 5.52407265e-02,\n",
       "        5.52407265e-02, 5.52407265e-02, 5.72277102e-02, 3.92012493e-01,\n",
       "        5.72277102e-02, 5.52407265e-02, 5.52407265e-02, 5.52407265e-02,\n",
       "        5.51725193e-02, 1.41041114e-02, 1.17672329e-02],\n",
       "       [9.06841787e-03, 1.14211289e-02, 1.36893355e-02, 5.27266636e-02,\n",
       "        5.28730406e-02, 5.30158909e-02, 5.51568286e-02, 5.72277102e-02,\n",
       "        3.92099935e-01, 5.73991267e-02, 5.75419770e-02, 5.76883540e-02,\n",
       "        5.77700417e-02, 5.77837511e-02, 1.45377987e-02],\n",
       "       [6.44114990e-03, 8.80604304e-03, 1.10897716e-02, 1.32965389e-02,\n",
       "        5.04385892e-02, 5.07242981e-02, 5.30158909e-02, 5.52407265e-02,\n",
       "        5.73991267e-02, 3.92362352e-01, 5.97769775e-02, 6.00697398e-02,\n",
       "        6.03013984e-02, 6.04688159e-02, 6.05685813e-02],\n",
       "       [3.98973973e-03, 6.43268221e-03, 8.79419594e-03, 1.10784973e-02,\n",
       "        1.32894854e-02, 5.04385892e-02, 5.28730406e-02, 5.52407265e-02,\n",
       "        5.75419770e-02, 5.97769775e-02, 4.29797165e-01, 6.22877814e-02,\n",
       "        6.25969741e-02, 6.28421767e-02, 6.30199915e-02],\n",
       "       [1.46054004e-03, 3.98342509e-03, 6.42461293e-03, 8.78833309e-03,\n",
       "        1.10784973e-02, 1.32965389e-02, 5.27266636e-02, 5.52407265e-02,\n",
       "        5.76883540e-02, 6.00697398e-02, 6.22877814e-02, 4.71147605e-01,\n",
       "        6.49665571e-02, 6.52914338e-02, 6.55491911e-02],\n",
       "       [1.04185746e-03, 1.46032072e-03, 3.98129523e-03, 6.42461293e-03,\n",
       "        8.79419594e-03, 1.10897716e-02, 1.36893355e-02, 5.51725193e-02,\n",
       "        5.77700417e-02, 6.03013984e-02, 6.25969741e-02, 6.49665571e-02,\n",
       "        5.16737103e-01, 6.78163100e-02, 6.81577073e-02],\n",
       "       [6.92066105e-04, 1.04193261e-03, 1.46032072e-03, 3.98342509e-03,\n",
       "        6.43268221e-03, 8.80604304e-03, 1.14211289e-02, 1.41041114e-02,\n",
       "        5.77837511e-02, 6.04688159e-02, 6.28421767e-02, 6.52914338e-02,\n",
       "        6.78163100e-02, 5.67006110e-01, 7.08496923e-02],\n",
       "       [4.14764771e-04, 6.92066105e-04, 1.04185746e-03, 1.46054004e-03,\n",
       "        3.98973973e-03, 6.44114990e-03, 9.06841787e-03, 1.17672329e-02,\n",
       "        1.45377987e-02, 6.05685813e-02, 6.30199915e-02, 6.55491911e-02,\n",
       "        6.81577073e-02, 7.08496923e-02, 6.22441269e-01]])"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Un avec une matrice de covariance ord\n",
    "# KV_inv = K_cov_matrix(M, 0.2)\n",
    "KV_inv = graph_kernel(a_width = 5, a_strength = 0.1, dim = M)\n",
    "KV_inv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-05T23:03:47.025143Z",
     "start_time": "2020-06-05T23:03:47.020159Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.62347437, 0.07191639, 0.07191639, 0.07191639, 0.07191639,\n",
       "        0.07191639, 0.01694371],\n",
       "       [0.07191639, 0.56850169, 0.07191639, 0.07191639, 0.07191639,\n",
       "        0.07191639, 0.07191639],\n",
       "       [0.07191639, 0.07191639, 0.56850169, 0.07191639, 0.07191639,\n",
       "        0.07191639, 0.07191639],\n",
       "       [0.07191639, 0.07191639, 0.07191639, 0.56850169, 0.07191639,\n",
       "        0.07191639, 0.07191639],\n",
       "       [0.07191639, 0.07191639, 0.07191639, 0.07191639, 0.56850169,\n",
       "        0.07191639, 0.07191639],\n",
       "       [0.07191639, 0.07191639, 0.07191639, 0.07191639, 0.07191639,\n",
       "        0.56850169, 0.07191639],\n",
       "       [0.01694371, 0.07191639, 0.07191639, 0.07191639, 0.07191639,\n",
       "        0.07191639, 0.62347437]])"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Un avec un graph kernel\n",
    "KU_inv = graph_kernel(a_width = 5, a_strength = 0.1, dim = N)\n",
    "KU_inv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-06T00:01:13.973082Z",
     "start_time": "2020-06-06T00:01:13.954905Z"
    }
   },
   "outputs": [],
   "source": [
    "# Entrainement\n",
    "import random\n",
    "from tqdm.auto import trange # Barre de progression pour les boules imbriquées\n",
    "\n",
    "# Hyperparamètres\n",
    "itr = 5    #    R = itr = iterations\n",
    "lr = 0.1    #    l = learning_rate\n",
    "R = 10 #    K = approx # Rang !!! (changer les termes pour uniformité)\n",
    "\n",
    "\n",
    "def KPMF(itr, lr, R, A, KU_inv, KV_inv):\n",
    "    \"\"\"\n",
    "    Algorithme :\n",
    "        KPMF avec descente du gradient\n",
    "    \n",
    "    Paramètres en entré : \n",
    "        A : Matrice pour l'entrainement (N * M)\n",
    "        \n",
    "        R : Rang souhaité pour les matrices\n",
    "        \n",
    "        KU_inv : Matrice de précision (N * N) sur les lignes de A\n",
    "        KV_inv : Matrice de précision (M * M) sur les colonnes de A\n",
    "        \n",
    "        itr : Nombre d'itérations\n",
    "        lr : Taux d'apprentissage\n",
    "    \n",
    "    \n",
    "    Paramètre en sortie :\n",
    "        imp_A : Matrice A avec les nouvelles données imputées\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    A = np.interp(A, (A.min(), A.max()), (-1, +1))\n",
    "    # Identifier les éléments présents dans la matrice\n",
    "    Z = np.asarray(A > 0, dtype = np.float64)\n",
    "    \n",
    "    # Enlever la moyenne (?) - trouver pourquoi\n",
    "    #A1d = np.ravel(A)\n",
    "    #mean = np.mean(A1d)\n",
    "    #A = A - mean\n",
    "    print(A.shape)\n",
    "    # Initialiser U et V\n",
    "    N = A.shape[0] # Nombre de lignes dans A\n",
    "    print(N)\n",
    "    M = A.shape[1] # Nombre de colones dans A\n",
    "    print(M)\n",
    "    \n",
    "    random.seed(12345)\n",
    "    U = np.random.randn(N, R) # Initialisation de U\n",
    "    \n",
    "    random.seed(12345)\n",
    "    V = np.random.randn(R, M) # Initialisation de V\n",
    "    \n",
    "    \n",
    "    sigma2 = 0.4 ** 2\n",
    "    \n",
    "       \n",
    "    \n",
    "    # Algorithme de gradient pour trouver les facteurs latents\n",
    "    for r in trange(itr):\n",
    "        # Pour chaque ligne et pour chaque colonne, si l'élément dans la cellule est plus haute que 0\n",
    "        for i in trange(N):\n",
    "            for j in trange(M):\n",
    "                if Z[i, j] > 0:\n",
    "                    e = A[i,j] - np.dot(U[i,:], V[:,j])\n",
    "                    \n",
    "                    U[i,:] = U[i,:] + lr * (V[:,j] - e.T * np.dot(KU_inv[i,:], U))\n",
    "                    V[:,j] = V[:,j] + lr * (U[i,:] - e.T * np.dot(V, KV_inv[:,j]))\n",
    "                    \n",
    "                    #U[i,:] + lr * (e.T * np.dot(KU_inv[i,:], U))\n",
    "                    # V[:,j] = V[:,j] + lr * (e.T * np.dot(V, KV_inv[:,j]))\n",
    "                    \n",
    "                    # e(n) denotes an N-dimensional unit vector with the nth component being one and others being zero\n",
    "                    #e = A[i, j] - np.dot(U[i, :], V[:, j])\n",
    "                    \n",
    "                    # Gradient pour U\n",
    "                    #tu1 = e * V[:, j]\n",
    "                    #tu2 = np.dot(KU_inv[i, :], U)\n",
    "                    #tu3 = lr * (tu1 - tu2)\n",
    "                    #U[i, :] = U[i, :] + tu3\n",
    "                    \n",
    "                    # Gradient pour V               \n",
    "                    #tv1 = e * U[i, :]\n",
    "                    #tv2 = np.dot(V, KV_inv[:, j])\n",
    "                    ##tv3 = lr * (tv1 - tv2)\n",
    "                    #print(tv1.shape, tv2.shape, tv3.shape)\n",
    "                    #V[:, j] = V[:, j] + tv3\n",
    "    \n",
    "    # Reformation de la matrice A\n",
    "    print(U)\n",
    "    print(V)\n",
    "    imp_A = np.dot(U, V)\n",
    "    #imp_A = imp_A + mean  # Pourquoi ???\n",
    "    \n",
    "    return imp_A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-06T00:01:14.327393Z",
     "start_time": "2020-06-06T00:01:14.264528Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7, 15)\n",
      "7\n",
      "15\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00e20d1139254717bc71f125a2ed3e42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5d92b1c1ce94de09f09dcd05fdb3383",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=7.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf376a12844542e19c914616e6527af0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=15.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "matmul: Input operand 1 has a mismatch in its core dimension 0, with gufunc signature (n?,k),(k,m?)->(n?,m?) (size 7 is different from 15)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-311-e4c52c7ecac0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mimp_A\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mKPMF\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mitr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mR\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mR\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mA\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0morigA\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mKU_inv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mKU_inv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mKV_inv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mKV_inv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-310-98a810a9cb30>\u001b[0m in \u001b[0;36mKPMF\u001b[1;34m(itr, lr, R, A, KU_inv, KV_inv)\u001b[0m\n\u001b[0;32m     70\u001b[0m                     \u001b[1;31m#V[:,j] = V[:,j] + lr * (U[i,:] - e.T * np.dot(V, KV_inv[:,j]))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m                     U[i,:] = -(np.matmul(sum(A - UV),\n\u001b[1;32m---> 72\u001b[1;33m                                          np.ones(N) * U[i,j])/sigma2) + lr * (\n\u001b[0m\u001b[0;32m     73\u001b[0m                         e.T * np.matmul(V,\n\u001b[0;32m     74\u001b[0m                                         KV_inv[:,j]))\n",
      "\u001b[1;31mValueError\u001b[0m: matmul: Input operand 1 has a mismatch in its core dimension 0, with gufunc signature (n?,k),(k,m?)->(n?,m?) (size 7 is different from 15)"
     ]
    }
   ],
   "source": [
    "imp_A = KPMF(itr = itr, lr = lr, R = R, A = origA, KU_inv = KU_inv, KV_inv = KV_inv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-05T23:00:43.214520Z",
     "start_time": "2020-06-05T23:00:43.209534Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7, 15)"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "OrigA.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Résultats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-05T21:59:42.511615Z",
     "start_time": "2020-06-05T21:59:42.506630Z"
    }
   },
   "outputs": [],
   "source": [
    "# Calcul du RMSE\n",
    "def get_RMSE(A_dense, imp_A):\n",
    "    \"\"\"\n",
    "    Paramètres en entrée : \n",
    "        A_dense : Matrice A dense (avec tous les éléments)\n",
    "        imp_A : Matrice A avec les éléments imputés\n",
    "    Paramètres en sortie : \n",
    "        RMSE : Erreur au carré\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    A1d = np.ravel(A_dense)\n",
    "    print(A1d)\n",
    "    A_1d = np.ravel(imp_A)\n",
    "    print(A_1d)\n",
    "    \n",
    "    # Calcul de l'erreur au carré\n",
    "    e = np.mean((A1d - A_1d) ** 2)\n",
    "    print(e)\n",
    "    \n",
    "    # Calcul du RMSE\n",
    "    RMSE = np.sqrt(e)\n",
    "    print(RMSE)\n",
    "    \n",
    "    return RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-05T21:59:43.039252Z",
     "start_time": "2020-06-05T21:59:42.874644Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[nan, nan, nan, ..., nan, nan, nan],\n",
       "       [nan, nan, nan, ..., nan, nan, nan],\n",
       "       [nan, nan, nan, ..., nan, nan, nan],\n",
       "       ...,\n",
       "       [nan, nan, nan, ..., nan, nan, nan],\n",
       "       [nan, nan, nan, ..., nan, nan, nan],\n",
       "       [nan, nan, nan, ..., nan, nan, nan]])"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat_hat = imp_A\n",
    "mat_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-05T21:48:11.542531Z",
     "start_time": "2020-06-05T21:48:11.498649Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([41.227, 45.891, 42.333, ..., 50.204, 51.683, 50.03 ])"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos = np.where((dense_mat != 0) & (sparse_mat == 0))\n",
    "dense_mat[pos]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat_hat = np.matmul(W, X.T)\n",
    "\n",
    "\n",
    "np.sqrt(np.sum((dense_mat[pos] - mat_hat[pos]) ** 2)/dense_mat[pos].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-05T21:47:19.397171Z",
     "start_time": "2020-06-05T21:47:19.393169Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[40.893 41.938 44.098 ... 50.204 51.683 50.03 ]\n",
      "[nan nan nan ... nan nan nan]\n",
      "nan\n",
      "nan\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_RMSE(dense_mat, imp_A)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Mettre ça dans la fin du code (ceci provient de MATLAB)  \n",
    "  \n",
    "  % Calculate the objective function with current U and V\n",
    "    tmpMat = mask.*((R - U*V').^2);\n",
    "    err = 0.5 * sum(tmpMat(:)) / (sigma_r^2);\n",
    "    for d = 1 : D\n",
    "        err = err + 0.5 * ((U(:,d))'*K_u_inv*(U(:,d)) + (V(:,d))'*K_v_inv*(V(:,d)));%* sigma_r^2; % FIXME: sigma_r\n",
    "    end\n",
    "    E(numIters) = err;\n",
    "    \n",
    "    n = sum(mask2(:));\n",
    "    tmpMat = mask2.*((R2 - U*V').^2);\n",
    "    RMSE(numIters) = sqrt(sum(tmpMat(:))/n);\n",
    "    \n",
    "    disp(['iter' ,int2str(numIters),', err=',num2str(err), ', rmse=', num2str(RMSE(numIters))]);\n",
    "\n",
    "    if (numIters > minIters  && (RMSE(numIters-1) - RMSE(numIters))/RMSE(numIters-1)<epsilon )\n",
    "        break;\n",
    "    end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Partie 2.3 : Test du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "colors=['r','b','g','c','m','k']\n",
    "plot.figure()\n",
    "#bs,RMSEs = zip(*PMF_RMSE)\n",
    "ws,bRMSEs = zip(*KPMF_RMSE)\n",
    "labels=[\"PMF\"]+[\"KPMF_\"+\"w\" for w in ws]\n",
    "plot.title(\"RMSE vs. regularization/diffusion rate\")\n",
    "for err,col,lbl in zip(bRMSEs,colors,labels): #((RMSEs,)+bRMSEs,colors,labels):\n",
    "    plot.plot(err, col, label=str(lbl))#(bs, err, col, label=str(lbl))\n",
    "plot.xlabel('Regularization rate')\n",
    "plot.ylabel('RMSE')\n",
    "plot.legend()\n",
    "plot.savefig(\"reg_rate_and_diffusion_RMSE.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Partie 3 : Sorties du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Partie 4 : Présentation des résultats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
