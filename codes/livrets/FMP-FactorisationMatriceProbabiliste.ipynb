{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Factorisation de matrice probabiliste\n",
    "\n",
    ">Présentation de la factorisation de matrice probabiliste (FMP).\n",
    "\n",
    "## Recherches associées\n",
    ">Ruslan Salakhutdinov, Andriy Mnih (2008). **Probabilistic Matrix Factorization.**\n",
    "\n",
    "\n",
    "## Codes sources\n",
    ">[**Dépôt 1**](https://github.com/xinychen/transdim/blob/master/experiments/Imputation-PMF-Gdata.ipynb) *Version Python*  \n",
    ">[**Dépôt 2**](https://github.com/stxupengyu/Probabilistic-Matrix-Factorization) *Version R*  \n",
    ">[**Code original**](http://www.cs.toronto.edu/~rsalakhu/code_BPMF/pmf.m) *Version MATLAB*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table des matières<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Factorisation-de-matrice-probabiliste\" data-toc-modified-id=\"Factorisation-de-matrice-probabiliste-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Factorisation de matrice probabiliste</a></span><ul class=\"toc-item\"><li><span><a href=\"#Recherches-associées\" data-toc-modified-id=\"Recherches-associées-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Recherches associées</a></span></li><li><span><a href=\"#Codes-sources\" data-toc-modified-id=\"Codes-sources-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Codes sources</a></span></li></ul></li><li><span><a href=\"#Mettre-l'environnement-en-place\" data-toc-modified-id=\"Mettre-l'environnement-en-place-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Mettre l'environnement en place</a></span></li><li><span><a href=\"#Charger-les-données-dans-l'environnement\" data-toc-modified-id=\"Charger-les-données-dans-l'environnement-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Charger les données dans l'environnement</a></span><ul class=\"toc-item\"><li><span><a href=\"#Préparer-les-données-pour-l'entrainement\" data-toc-modified-id=\"Préparer-les-données-pour-l'entrainement-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Préparer les données pour l'entrainement</a></span></li></ul></li><li><span><a href=\"#Définir-les-fonctions-pour-le-modèle\" data-toc-modified-id=\"Définir-les-fonctions-pour-le-modèle-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Définir les fonctions pour le modèle</a></span><ul class=\"toc-item\"><li><span><a href=\"#Fonctions-pour-calculer-l'erreur-du-modèle\" data-toc-modified-id=\"Fonctions-pour-calculer-l'erreur-du-modèle-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>Fonctions pour calculer l'erreur du modèle</a></span></li><li><span><a href=\"#Fonction-pour-arrondir-les-éléments-d'une-liste\" data-toc-modified-id=\"Fonction-pour-arrondir-les-éléments-d'une-liste-4.2\"><span class=\"toc-item-num\">4.2&nbsp;&nbsp;</span>Fonction pour arrondir les éléments d'une liste</a></span></li><li><span><a href=\"#Définir-le-modèle\" data-toc-modified-id=\"Définir-le-modèle-4.3\"><span class=\"toc-item-num\">4.3&nbsp;&nbsp;</span>Définir le modèle</a></span></li></ul></li><li><span><a href=\"#Entrainer-le-modèle\" data-toc-modified-id=\"Entrainer-le-modèle-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Entrainer le modèle</a></span><ul class=\"toc-item\"><li><span><a href=\"#Générer-les-combinaisons-d'hyperparamètres\" data-toc-modified-id=\"Générer-les-combinaisons-d'hyperparamètres-5.1\"><span class=\"toc-item-num\">5.1&nbsp;&nbsp;</span>Générer les combinaisons d'hyperparamètres</a></span></li><li><span><a href=\"#Spécifier-les-autres-paramètres-du-modèle\" data-toc-modified-id=\"Spécifier-les-autres-paramètres-du-modèle-5.2\"><span class=\"toc-item-num\">5.2&nbsp;&nbsp;</span>Spécifier les autres paramètres du modèle</a></span></li><li><span><a href=\"#Spécifier-les-paramètres-de-l'entrainement\" data-toc-modified-id=\"Spécifier-les-paramètres-de-l'entrainement-5.3\"><span class=\"toc-item-num\">5.3&nbsp;&nbsp;</span>Spécifier les paramètres de l'entrainement</a></span></li><li><span><a href=\"#Sélectionner-les-hyperparamètres-du-modèle\" data-toc-modified-id=\"Sélectionner-les-hyperparamètres-du-modèle-5.4\"><span class=\"toc-item-num\">5.4&nbsp;&nbsp;</span>Sélectionner les hyperparamètres du modèle</a></span><ul class=\"toc-item\"><li><span><a href=\"#Sauvegarder-les-informations-sur-la-sélection-d'hyperparamètre\" data-toc-modified-id=\"Sauvegarder-les-informations-sur-la-sélection-d'hyperparamètre-5.4.1\"><span class=\"toc-item-num\">5.4.1&nbsp;&nbsp;</span>Sauvegarder les informations sur la sélection d'hyperparamètre</a></span><ul class=\"toc-item\"><li><span><a href=\"#Sauvegarder-les-informations-sur-la-distribution-des-paramètres\" data-toc-modified-id=\"Sauvegarder-les-informations-sur-la-distribution-des-paramètres-5.4.1.1\"><span class=\"toc-item-num\">5.4.1.1&nbsp;&nbsp;</span>Sauvegarder les informations sur la distribution des paramètres</a></span></li><li><span><a href=\"#Sauvegarder-les-informations-DURANT-l'entrainement\" data-toc-modified-id=\"Sauvegarder-les-informations-DURANT-l'entrainement-5.4.1.2\"><span class=\"toc-item-num\">5.4.1.2&nbsp;&nbsp;</span>Sauvegarder les informations DURANT l'entrainement</a></span></li><li><span><a href=\"#Sauvegarder-les-informations-FINALES-des-entrainements\" data-toc-modified-id=\"Sauvegarder-les-informations-FINALES-des-entrainements-5.4.1.3\"><span class=\"toc-item-num\">5.4.1.3&nbsp;&nbsp;</span>Sauvegarder les informations FINALES des entrainements</a></span></li></ul></li></ul></li><li><span><a href=\"#Entrainer-le-meilleur-modèle\" data-toc-modified-id=\"Entrainer-le-meilleur-modèle-5.5\"><span class=\"toc-item-num\">5.5&nbsp;&nbsp;</span>Entrainer le meilleur modèle</a></span><ul class=\"toc-item\"><li><span><a href=\"#Sauvegarder-les-informations-sur-l'entrainement-du-meilleur-modèle\" data-toc-modified-id=\"Sauvegarder-les-informations-sur-l'entrainement-du-meilleur-modèle-5.5.1\"><span class=\"toc-item-num\">5.5.1&nbsp;&nbsp;</span>Sauvegarder les informations sur l'entrainement du meilleur modèle</a></span><ul class=\"toc-item\"><li><span><a href=\"#Sauvegarder-la-matrice-prédite\" data-toc-modified-id=\"Sauvegarder-la-matrice-prédite-5.5.1.1\"><span class=\"toc-item-num\">5.5.1.1&nbsp;&nbsp;</span>Sauvegarder la matrice prédite</a></span></li><li><span><a href=\"#Sauvegarder-avec-les-nouvelles-valeurs-imputées\" data-toc-modified-id=\"Sauvegarder-avec-les-nouvelles-valeurs-imputées-5.5.1.2\"><span class=\"toc-item-num\">5.5.1.2&nbsp;&nbsp;</span>Sauvegarder avec les nouvelles valeurs imputées</a></span></li></ul></li></ul></li></ul></li><li><span><a href=\"#Sauvegarder-les-information-pour-la-présentation-des-résultats\" data-toc-modified-id=\"Sauvegarder-les-information-pour-la-présentation-des-résultats-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Sauvegarder les information pour la présentation des résultats</a></span><ul class=\"toc-item\"><li><span><a href=\"#Sauvegarder-le-tableau-pour-la-comparaison-intermodèles\" data-toc-modified-id=\"Sauvegarder-le-tableau-pour-la-comparaison-intermodèles-6.1\"><span class=\"toc-item-num\">6.1&nbsp;&nbsp;</span>Sauvegarder le tableau pour la comparaison intermodèles</a></span></li><li><span><a href=\"#Sauvegarder-les-données-pour-la-présentation-graphique\" data-toc-modified-id=\"Sauvegarder-les-données-pour-la-présentation-graphique-6.2\"><span class=\"toc-item-num\">6.2&nbsp;&nbsp;</span>Sauvegarder les données pour la présentation graphique</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mettre l'environnement en place"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-20T21:45:16.960152Z",
     "start_time": "2020-10-20T21:45:16.523734Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import time\n",
    "from itertools import product\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.io as sio\n",
    "from numpy import linalg as LA\n",
    "from numpy.linalg import inv as inv\n",
    "from numpy.linalg import pinv as pinv\n",
    "from tqdm import tqdm, trange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-20T21:45:16.975152Z",
     "start_time": "2020-10-20T21:45:16.962153Z"
    }
   },
   "outputs": [],
   "source": [
    "os.chdir(\"./\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Charger les données dans l'environnement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-20T21:45:16.991153Z",
     "start_time": "2020-10-20T21:45:16.977154Z"
    }
   },
   "outputs": [],
   "source": [
    "parametres = {\n",
    "    \"dossier_donnees\": \"data\",\n",
    "    \"dossier_experience\": \"exp\",\n",
    "    \"sousdossier\": \"simulation_simple\",\n",
    "    \"fichier_donnees\": \"SimSimple_100\",\n",
    "    \"fichier_binaire\": \"SimSimple_100_10\",\n",
    "    \"manquants\": \"10\",\n",
    "    \"modele\": \"FMP\",\n",
    "    \"version\": \"v001\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-20T21:45:17.006154Z",
     "start_time": "2020-10-20T21:45:16.993151Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le dossier pour l'expérience existe déjà\n"
     ]
    }
   ],
   "source": [
    "# Créer le dossier s'il n'existe pas\n",
    "if not os.path.exists(os.path.join(parametres[\"dossier_experience\"], \n",
    "                                   parametres[\"sousdossier\"])):\n",
    "    print(\"Le dossier pour l'expérience vient d'être créé\")\n",
    "    os.makedirs(os.path.join(parametres[\"dossier_experience\"], \n",
    "                             parametres[\"sousdossier\"]))\n",
    "print(\"Le dossier pour l'expérience existe déjà\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-20T21:45:17.021151Z",
     "start_time": "2020-10-20T21:45:17.008152Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data\\simulation_simple\\SimSimple_100.mat\n"
     ]
    }
   ],
   "source": [
    "ch_fichier_donnees = \"{:}.mat\".format(os.path.join(parametres[\"dossier_donnees\"], \n",
    "                                                   parametres[\"sousdossier\"], \n",
    "                                                   parametres[\"fichier_donnees\"]))\n",
    "mat_complet = sio.loadmat(ch_fichier_donnees)[\"mat\"]\n",
    "tqdm.write(ch_fichier_donnees)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-20T21:45:17.037152Z",
     "start_time": "2020-10-20T21:45:17.023153Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data\\simulation_simple\\SimSimple_100_10.mat\n"
     ]
    }
   ],
   "source": [
    "ch_fichier_binaire = \"{:}.mat\".format(os.path.join(parametres[\"dossier_donnees\"], \n",
    "                                                   parametres[\"sousdossier\"], \n",
    "                                                   parametres[\"fichier_binaire\"]))\n",
    "mat_binaire = sio.loadmat(ch_fichier_binaire)[\"mat\"]\n",
    "tqdm.write(ch_fichier_binaire)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-20T21:45:17.052151Z",
     "start_time": "2020-10-20T21:45:17.039159Z"
    }
   },
   "outputs": [],
   "source": [
    "mat_manquants = mat_complet * mat_binaire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-20T21:45:17.071156Z",
     "start_time": "2020-10-20T21:45:17.054153Z"
    }
   },
   "outputs": [],
   "source": [
    "# Déterminer les index\n",
    "index = np.where((mat_complet != 0) & (mat_binaire == 0))\n",
    "index_complet = np.where((mat_complet != 0)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-20T21:45:17.084153Z",
     "start_time": "2020-10-20T21:45:17.073155Z"
    }
   },
   "outputs": [],
   "source": [
    "def nommation_fichier(dossier_experience, fichier_experience,\n",
    "                      parametres_entrainement, fonction_fichier, extension):\n",
    "    \n",
    "    # Ajouter un _ avant la fonction\n",
    "    if fonction_fichier != \"\":\n",
    "        fonction_fichier = \"_\" + fonction_fichier\n",
    "        \n",
    "    nom_fichier = \"{:}{:}_r{:}-e{:}-l{:}-m{:}{:}{:}\".format(\n",
    "        dossier_experience, fichier_experience,\n",
    "        parametres_entrainement[\"rang\"],\n",
    "        str(parametres_entrainement[\"init_hyper\"][\"epsilon\"]).replace('.', ''),\n",
    "        str(parametres_entrainement[\"init_hyper\"][\"_lambda\"]).replace('.', ''),\n",
    "        str(parametres_entrainement[\"init_hyper\"][\"momentum\"]).replace('.', ''),\n",
    "        fonction_fichier, extension)\n",
    "    return nom_fichier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Préparer les données pour l'entrainement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-20T21:45:17.116151Z",
     "start_time": "2020-10-20T21:45:17.087152Z"
    }
   },
   "outputs": [],
   "source": [
    "# Données pour l'entrainement\n",
    "train_data = np.zeros((mat_manquants[mat_manquants > 0].shape[0], 3))\n",
    "\n",
    "start_idx = 0\n",
    "\n",
    "for i in range(mat_manquants.shape[0]):\n",
    "    for t in range(mat_manquants.shape[1]):\n",
    "        if mat_manquants[i, t] > 0:\n",
    "            train_data[start_idx, 0] = i # + 1  # User ID\n",
    "            train_data[start_idx, 1] = t # + 1  # Product ID\n",
    "            train_data[start_idx, 2] = mat_manquants[i, t]  # Rating\n",
    "            start_idx += 1\n",
    "\n",
    "# DonnÃ©es pour la validation\n",
    "validation_mat = mat_complet.copy()\n",
    "\n",
    "validation_mat[mat_manquants > 0] = 0\n",
    "\n",
    "test_data = np.zeros((validation_mat[validation_mat > 0].shape[0], 3))\n",
    "\n",
    "start_idx = 0\n",
    "for i in range(validation_mat.shape[0]):\n",
    "    for t in range(validation_mat.shape[1]):\n",
    "        if validation_mat[i, t] > 0:\n",
    "            test_data[start_idx, 0] = i #+ 1  # User ID\n",
    "            test_data[start_idx, 1] = t #+ 1  # Product ID\n",
    "            test_data[start_idx, 2] = validation_mat[i, t]  # Rating\n",
    "            start_idx += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Définir les fonctions pour le modèle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fonctions pour calculer l'erreur du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-20T21:45:17.132151Z",
     "start_time": "2020-10-20T21:45:17.118151Z"
    }
   },
   "outputs": [],
   "source": [
    "def MAPE(mat_complet, mat_hat, index):\n",
    "    mape = np.sum(\n",
    "        np.abs(mat_complet[index] - mat_hat[index]) /\n",
    "        mat_complet[index]) / mat_complet[index].shape[0]\n",
    "    return mape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-20T21:45:17.147306Z",
     "start_time": "2020-10-20T21:45:17.134152Z"
    }
   },
   "outputs": [],
   "source": [
    "def RMSE(mat_complet, mat_hat, index):\n",
    "    rmse = np.sqrt(\n",
    "        np.sum((mat_complet[index] - mat_hat[index])**2) /\n",
    "        mat_complet[index].shape[0])\n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fonction pour arrondir les éléments d'une liste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-20T21:45:17.162307Z",
     "start_time": "2020-10-20T21:45:17.148307Z"
    }
   },
   "outputs": [],
   "source": [
    "def round_list_elements(liste, virgule=3):\n",
    "    rounded_list = [round(num, virgule) for num in liste]\n",
    "    return rounded_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Définir le modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-20T21:45:17.194310Z",
     "start_time": "2020-10-20T21:45:17.164309Z"
    }
   },
   "outputs": [],
   "source": [
    "def pmf(train_vec,\n",
    "        val_vec,\n",
    "        num_feat,\n",
    "        epsilon,\n",
    "        _lambda,\n",
    "        momentum,\n",
    "        maxepoch,\n",
    "        num_batches,\n",
    "        batch_size,\n",
    "        max_early_stop=20,\n",
    "        max_plateau_stop=20):\n",
    "    # Initialisation des listes\n",
    "    test_rmse_list = []\n",
    "    train_rmse_list = []\n",
    "    gen_rmse_list = []\n",
    "\n",
    "    ## Initialisation du paramÃ¨tre d'arrÃªt precoce\n",
    "    iter_early_stop = 0\n",
    "    plateau_stop = 0\n",
    "    # mean subtraction\n",
    "    mean_inv = np.mean(train_vec[:, 2])\n",
    "\n",
    "    pairs_tr = train_vec.shape[0]\n",
    "    pairs_va = val_vec.shape[0]\n",
    "\n",
    "    # 1-p-i, 2-m-c\n",
    "    num_inv = int(max(np.amax(train_vec[:, 0]), np.amax(val_vec[:, 0]))) + 1\n",
    "    num_com = int(max(np.amax(train_vec[:, 1]), np.amax(val_vec[:, 1]))) + 1\n",
    "\n",
    "    incremental = False\n",
    "    if ((not incremental) or (w_C is None)):\n",
    "        # initialize\n",
    "        epoch = 0\n",
    "        np.random.seed(2020)\n",
    "        w_C = 0.1 * np.random.randn(num_com, num_feat)\n",
    "        np.random.seed(2020)\n",
    "        w_I = 0.1 * np.random.randn(num_inv, num_feat)\n",
    "\n",
    "        w_C_inc = np.zeros((num_com, num_feat))\n",
    "        w_I_inc = np.zeros((num_inv, num_feat))\n",
    "\n",
    "    # Listes pour les normes\n",
    "    liste_W = list()\n",
    "    liste_X = list()\n",
    "\n",
    "    for i in trange(maxepoch, desc=\"ItÃ©rations\", leave=False, position=1):\n",
    "        epoch += 1\n",
    "\n",
    "        # Shuffle training truples\n",
    "        shuffled_order = np.arange(train_vec.shape[0])\n",
    "        # np.random.seed(2020)\n",
    "        np.random.shuffle(shuffled_order)\n",
    "\n",
    "        # Batch update\n",
    "        for batch in list(range(num_batches)):\n",
    "            batch_idx = np.mod(\n",
    "                np.arange(batch_size * batch, batch_size * (batch + 1)),\n",
    "                shuffled_order.shape[0])\n",
    "\n",
    "            batch_invID = np.array(train_vec[shuffled_order[batch_idx], 0],\n",
    "                                   dtype='int32')\n",
    "            batch_comID = np.array(train_vec[shuffled_order[batch_idx], 1],\n",
    "                                   dtype='int32')\n",
    "\n",
    "            # Compute Objective Function\n",
    "            pred_out = np.sum(np.multiply(w_I[batch_invID, :],\n",
    "                                          w_C[batch_comID, :]),\n",
    "                              axis=1)  # mean_inv subtracted\n",
    "\n",
    "            rawErr = pred_out - train_vec[shuffled_order[batch_idx],\n",
    "                                          2] + mean_inv\n",
    "\n",
    "            # Compute gradients\n",
    "            Ix_C = 2 * np.multiply(rawErr[:, np.newaxis], w_I[\n",
    "                batch_invID, :]) + _lambda * w_C[batch_comID, :]\n",
    "            Ix_I = 2 * np.multiply(rawErr[:, np.newaxis], w_C[\n",
    "                batch_comID, :]) + _lambda * w_I[batch_invID, :]\n",
    "\n",
    "            dw_C = np.zeros((num_com, num_feat))\n",
    "            dw_I = np.zeros((num_inv, num_feat))\n",
    "\n",
    "            # loop to aggreate the gradients of the same element\n",
    "            for i in list(range(batch_size)):\n",
    "                dw_C[batch_comID[i], :] += Ix_C[i, :]\n",
    "                dw_I[batch_invID[i], :] += Ix_I[i, :]\n",
    "\n",
    "            # Update with momentum\n",
    "            w_C_inc = momentum * w_C_inc + epsilon * dw_C / batch_size\n",
    "            w_I_inc = momentum * w_I_inc + epsilon * dw_I / batch_size\n",
    "\n",
    "            w_C = w_C - w_C_inc\n",
    "            w_I = w_I - w_I_inc\n",
    "\n",
    "        # Calcul de la convergence\n",
    "        norme_w = np.linalg.norm(w_C, ord=\"fro\")\n",
    "        liste_W.append(norme_w)\n",
    "\n",
    "        norme_x = np.linalg.norm(w_I, ord=\"fro\")\n",
    "        liste_X.append(norme_x)\n",
    "\n",
    "        # Compute train error\n",
    "        train_out = np.sum(np.multiply(\n",
    "            w_I[np.array(train_vec[:, 0], dtype='int32'), :],\n",
    "            w_C[np.array(train_vec[:, 1], dtype='int32'), :]),\n",
    "                           axis=1)\n",
    "        error_train = train_out - train_vec[:, 2] + mean_inv\n",
    "        train_rmse = LA.norm(error_train) / np.sqrt(len(train_vec))\n",
    "\n",
    "        train_rmse_list.append(train_rmse)\n",
    "\n",
    "        # Compute validation error\n",
    "        test_out = np.sum(np.multiply(\n",
    "            w_I[np.array(val_vec[:, 0], dtype='int32'), :],\n",
    "            w_C[np.array(val_vec[:, 1], dtype='int32'), :]),\n",
    "                          axis=1)\n",
    "        error_test = test_out - val_vec[:, 2] + mean_inv\n",
    "        test_rmse = LA.norm(error_test) / np.sqrt(len(val_vec))\n",
    "\n",
    "        test_rmse_list.append(test_rmse)\n",
    "\n",
    "        # Compute general error (NOT)\n",
    "\n",
    "        perfo_fin = dict(test_rmse=test_rmse, train_rmse=train_rmse)\n",
    "\n",
    "        # Print information\n",
    "        if epoch % 50 == 0:\n",
    "            tqdm.write(\n",
    "                ('Epoch {:} | Train RMSE:{:.6f} | Test RMSE:{:.6f}'.format(\n",
    "                    epoch, train_rmse, test_rmse)))\n",
    "\n",
    "        etude_hyper = dict(W=liste_W, X=liste_X)\n",
    "        if np.isnan(test_rmse) == True:\n",
    "            break\n",
    "\n",
    "        ## Module d'arrÃªt prÃ©code (Ã©viter le surentrainement)\n",
    "        if np.round(test_rmse_list[len(test_rmse_list) - 2], 6) < np.round(\n",
    "                test_rmse, 6):\n",
    "            iter_early_stop = iter_early_stop + 1\n",
    "            if iter_early_stop == max_early_stop:\n",
    "                break\n",
    "        if np.round(test_rmse_list[len(test_rmse_list) - 2], 6) > np.round(\n",
    "                test_rmse, 6):\n",
    "            iter_early_stop = 0\n",
    "\n",
    "        # Module d'arrÃªt plateau\n",
    "        if np.round(test_rmse_list[len(test_rmse_list) - 2],\n",
    "                    6) == np.round(test_rmse, 6):\n",
    "            plateau_stop = plateau_stop + 1\n",
    "            if plateau_stop == max_plateau_stop:\n",
    "                break\n",
    "        if np.round(test_rmse_list[len(test_rmse_list) - 2], 6) > np.round(\n",
    "                test_rmse, 6):\n",
    "            plateau_stop = 0\n",
    "    return w_I, w_C, train_rmse_list, test_rmse_list, perfo_fin, etude_hyper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entrainer le modèle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Générer les combinaisons d'hyperparamètres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-20T21:45:17.210308Z",
     "start_time": "2020-10-20T21:45:17.196308Z"
    }
   },
   "outputs": [],
   "source": [
    "# Spécifier les valeurs minimum et maximum des hyperparamètres\n",
    "min_rang = 10\n",
    "max_rang = 50\n",
    "min_epsilon = 0.00001\n",
    "max_epsilon = 0.02\n",
    "min_lambda = 0.001\n",
    "max_lambda = 0.999\n",
    "min_momentum = 0.001\n",
    "max_momentum = 0.999\n",
    "\n",
    "# Spécifier le nombre de points à l'intérieur du domaine\n",
    "nb_ecarts = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-20T21:45:17.242308Z",
     "start_time": "2020-10-20T21:45:17.225307Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de combinaisons possibles : 9000\n",
      "Configurations possibles : \n",
      "[10, 15, 20, 25, 30, 35, 40, 45, 50]\n",
      "[1e-05, 0.00223, 0.00445, 0.00667, 0.00889, 0.01112, 0.01334, 0.01556, 0.01778, 0.02]\n",
      "[0.001, 0.1119, 0.2228, 0.3337, 0.4446, 0.5554, 0.6663, 0.7772, 0.8881, 0.999]\n",
      "[0.001, 0.1119, 0.2228, 0.3337, 0.4446, 0.5554, 0.6663, 0.7772, 0.8881, 0.999]\n"
     ]
    }
   ],
   "source": [
    "param_grid = dict(rang_list=[10, 15, 20, 25, 30, 35, 40, 45, 50],\n",
    "                  epsilon_list=round_list_elements(\n",
    "                      list(np.linspace(min_epsilon, max_epsilon, nb_ecarts)),\n",
    "                      5),\n",
    "                  lambda_list=round_list_elements(\n",
    "                      list(np.linspace(min_lambda, max_lambda, nb_ecarts)), 4),\n",
    "                  momentum_list=round_list_elements(\n",
    "                      list(np.linspace(min_momentum, max_momentum, nb_ecarts)),\n",
    "                      4))\n",
    "\n",
    "combinations_list = [\n",
    "    list(x)\n",
    "    for x in product(param_grid[\"rang_list\"], param_grid[\"epsilon_list\"],\n",
    "                     param_grid[\"lambda_list\"], param_grid[\"momentum_list\"])\n",
    "]\n",
    "\n",
    "tqdm.write(\n",
    "    (\"Nombre de combinaisons possibles : {:}\".format(len(combinations_list))))\n",
    "tqdm.write((\"Configurations possibles : \\n{}\\n{}\\n{}\\n{}\".format(\n",
    "    param_grid[\"rang_list\"], param_grid[\"epsilon_list\"],\n",
    "    param_grid[\"lambda_list\"], param_grid[\"momentum_list\"])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spécifier les autres paramètres du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-20T21:45:17.306309Z",
     "start_time": "2020-10-20T21:45:17.288346Z"
    }
   },
   "outputs": [],
   "source": [
    "maxepoch = 3 #1000\n",
    "max_early_stop = 2\n",
    "max_plateau_stop = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spécifier les paramètres de l'entrainement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-20T21:45:17.354308Z",
     "start_time": "2020-10-20T21:45:17.348308Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre total de combinaisons à entrainer: 1\n"
     ]
    }
   ],
   "source": [
    "# Définir le nombre de combinaisons totales à considérer pour la recherche d'hyperparamètres\n",
    "prop_eval = 0.0001\n",
    "nombre_eval = np.int(np.round(len(combinations_list) * prop_eval, 0))\n",
    "tqdm.write(\"Nombre total de combinaisons à entrainer: {:}\".format(nombre_eval))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-20T21:45:17.402309Z",
     "start_time": "2020-10-20T21:45:17.392308Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    }
   ],
   "source": [
    "## Creer un dataframe de toutes les configurations (sauvegarder les configurations choisies)\n",
    "params = list()\n",
    "random.seed(2020)\n",
    "for i in trange(nombre_eval, desc = \"Initialisation des paramÃ¨tres\", leave = False):\n",
    "    random_params = {k: random.sample(v, 1)[0] for k, v in param_grid.items()}\n",
    "    params.append(random_params)\n",
    "    \n",
    "params_df = pd.DataFrame(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-20T21:45:17.448307Z",
     "start_time": "2020-10-20T21:45:17.443308Z"
    }
   },
   "outputs": [],
   "source": [
    "fichier_experience = \"{a[fichier_binaire]}_{a[modele]}_{a[version]}\".format(a = parametres)\n",
    "ch_fichier_experience = os.path.join(parametres[\"dossier_experience\"], parametres[\"sousdossier\"], fichier_experience)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-20T21:45:17.511568Z",
     "start_time": "2020-10-20T21:45:17.476531Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exp\\simulation_simple\\SimSimple_100_10_FMP_v001_RandomParametres.ftr\n"
     ]
    }
   ],
   "source": [
    "fichier_combinaisons = \"{:}_{:}.ftr\".format(ch_fichier_experience, \"RandomParametres\")\n",
    "params_df.to_feather(fichier_combinaisons)\n",
    "\n",
    "tqdm.write(fichier_combinaisons)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sélectionner les hyperparamètres du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-20T21:45:17.923568Z",
     "start_time": "2020-10-20T21:45:17.543532Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Recherche hypers:   0%|                                                                          | 0/1 [00:00<?, ?it/s]\n",
      "ItÃ©rations:   0%|                                                                               | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "ItÃ©rations:  33%|███████████████████████▋                                               | 1/3 [00:00<00:00,  8.70it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrainement avec : Rang: 20 {'epsilon': 0.01556, '_lambda': 0.7772, 'momentum': 0.7772}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "ItÃ©rations:  67%|███████████████████████████████████████████████▎                       | 2/3 [00:00<00:00,  8.52it/s]\u001b[A\n",
      "ItÃ©rations: 100%|███████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00,  8.66it/s]\u001b[A\n",
      "Recherche hypers: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  2.75it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance du modele :{'test_rmse': 23.327669585035636, 'train_rmse': 23.325083436314095}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "entrainement_dict = dict()\n",
    "\n",
    "for i in trange(len(params_df),\n",
    "                total=len(params_df),\n",
    "                position=0,\n",
    "                leave=True,\n",
    "                desc=\"Recherche hypers\"):\n",
    "    random_params = params_df.iloc[i]\n",
    "\n",
    "    ## Premier Ã©lÃ©ment : Rang\n",
    "    rang = np.int(random_params[\"rang_list\"])\n",
    "\n",
    "    init_hyper = dict(epsilon=random_params[\"epsilon_list\"],\n",
    "                      _lambda=random_params[\"lambda_list\"],\n",
    "                      momentum=random_params[\"momentum_list\"])\n",
    "\n",
    "    param_utils = dict(\n",
    "        rang=rang,\n",
    "        epsilon=init_hyper[\"epsilon\"],\n",
    "        _lambda=init_hyper[\"_lambda\"],\n",
    "        momentum=init_hyper[\"momentum\"],\n",
    "        init_hyper=init_hyper)  # PrÃ©paration pour le suivant rapport\n",
    "\n",
    "    tqdm.write((\"Entrainement avec : Rang: {:} {:}\".format(\n",
    "        rang, param_utils[\"init_hyper\"])))\n",
    "\n",
    "    U, V, train_rmse_list, test_rmse_list, perfo_fin, etude_hyper = pmf(\n",
    "        train_vec=train_data,\n",
    "        val_vec=test_data,\n",
    "        num_feat=rang,\n",
    "        epsilon=param_utils[\"epsilon\"],\n",
    "        _lambda=param_utils[\"_lambda\"],\n",
    "        momentum=param_utils[\"momentum\"],\n",
    "        maxepoch=maxepoch,\n",
    "        num_batches=50,\n",
    "        batch_size=500,\n",
    "        max_early_stop=max_early_stop,\n",
    "        max_plateau_stop=max_plateau_stop)\n",
    "\n",
    "    mat_hat = np.dot(U, V.T)\n",
    "\n",
    "    metriques_listes = dict(test_rmse_list=test_rmse_list,\n",
    "                            train_rmse_list=train_rmse_list)\n",
    "\n",
    "    ## Mettre dans un dictionaire de tous les entrainements\n",
    "    index_entr = \"index {:}\".format(i)\n",
    "\n",
    "    entrainement_dict[index_entr] = {}\n",
    "    entrainement_dict[index_entr][\"parametres\"] = param_utils\n",
    "    entrainement_dict[index_entr][\"metriques_listes\"] = metriques_listes\n",
    "    entrainement_dict[index_entr][\"metriques_finales\"] = perfo_fin\n",
    "    entrainement_dict[index_entr][\"etude_hyper\"] = etude_hyper\n",
    "    tqdm.write((\"Performance du modele :{:}\".format(perfo_fin)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sauvegarder les informations sur la sélection d'hyperparamètre"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sauvegarder les informations sur la distribution des paramètres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-20T21:45:17.939568Z",
     "start_time": "2020-10-20T21:45:17.924530Z"
    }
   },
   "outputs": [],
   "source": [
    "hyper_liste = []\n",
    "for i in range(len(entrainement_dict)):\n",
    "    index = \"index {:}\".format(i)\n",
    "\n",
    "    df_etude_hyper = pd.DataFrame(entrainement_dict[index][\"etude_hyper\"])\n",
    "    df_etude_hyper['iteration'] = df_etude_hyper.index\n",
    "    df_etude_hyper[\"entrainement_no\"] = i + 1\n",
    "\n",
    "    hyper_liste.append(df_etude_hyper)\n",
    "\n",
    "df_etude_hyper = pd.concat(hyper_liste)\n",
    "df_etude_hyper = df_etude_hyper.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-20T21:45:17.955538Z",
     "start_time": "2020-10-20T21:45:17.942532Z"
    }
   },
   "outputs": [],
   "source": [
    "# Sauvegarder le fichier\n",
    "fichier_HyperDistribution = \"{:}_fichier_HyperDistribution.ftr\".format(ch_fichier_experience)\n",
    "df_etude_hyper.to_feather(fichier_HyperDistribution)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sauvegarder les informations DURANT l'entrainement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-20T21:45:17.971539Z",
     "start_time": "2020-10-20T21:45:17.957531Z"
    }
   },
   "outputs": [],
   "source": [
    "df_list = []\n",
    "for i in range(len(entrainement_dict)):\n",
    "    index = \"index {:}\".format(i)\n",
    "\n",
    "    listes_df = pd.DataFrame(entrainement_dict[index][\"metriques_listes\"])\n",
    "    listes_df['iteration'] = listes_df.index  # Colonne pour les itÃ©rations\n",
    "\n",
    "    listes_df[\"rang\"] = entrainement_dict[index][\"parametres\"][\"rang\"]\n",
    "    listes_df[\"epsilon\"] = entrainement_dict[index][\"parametres\"][\"epsilon\"]\n",
    "    listes_df[\"_lambda\"] = entrainement_dict[index][\"parametres\"][\"_lambda\"]\n",
    "    listes_df[\"momentum\"] = entrainement_dict[index][\"parametres\"][\"momentum\"]\n",
    "    listes_df[\"entrainement_no\"] = i + 1  ## FOR LOOP\n",
    "\n",
    "    df_list.append(listes_df)\n",
    "\n",
    "listes_df = pd.concat(df_list)\n",
    "listes_df = listes_df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-20T21:45:17.987567Z",
     "start_time": "2020-10-20T21:45:17.973536Z"
    }
   },
   "outputs": [],
   "source": [
    "# Sauvegarder le fichier\n",
    "fichier_HyperEntrainement = \"{:}_fichier_HyperEntrainement.ftr\".format(ch_fichier_experience)\n",
    "df_etude_hyper.to_feather(fichier_HyperEntrainement)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sauvegarder les informations FINALES des entrainements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-20T21:45:18.018555Z",
     "start_time": "2020-10-20T21:45:17.988532Z"
    }
   },
   "outputs": [],
   "source": [
    "test_list = []\n",
    "for i in entrainement_dict:\n",
    "    dict1 = {}\n",
    "    dict1.update(\n",
    "        dict(\n",
    "            rmse_test=entrainement_dict[i][\"metriques_finales\"][\"test_rmse\"],\n",
    "            rmse_train=entrainement_dict[i][\"metriques_finales\"][\"train_rmse\"],\n",
    "            rmse_gen= \"0\", #entrainement_dict[i][\"metriques_finales\"][\"gen_rmse\"],\n",
    "            rang=entrainement_dict[i][\"parametres\"][\"rang\"],\n",
    "            epsilon=entrainement_dict[i][\"parametres\"][\"init_hyper\"][\"epsilon\"],\n",
    "            momentum=entrainement_dict[i][\"parametres\"][\"init_hyper\"][\"momentum\"],\n",
    "            _lambda=entrainement_dict[i][\"parametres\"][\"init_hyper\"][\"_lambda\"]))\n",
    "\n",
    "    test_list.append(dict1)\n",
    "\n",
    "df = pd.DataFrame(test_list)\n",
    "\n",
    "df['config_rang'] = df[['epsilon', 'momentum', \"_lambda\"]].apply(lambda x: ', '.join(x.astype(str)), axis=1)\n",
    "df['config_epsilon'] = df[['rang', 'momentum', \"_lambda\"]].apply(lambda x: ', '.join(x.astype(str)), axis=1)\n",
    "df['config_momentum'] = df[['rang', 'epsilon', \"_lambda\"]].apply(lambda x: ', '.join(x.astype(str)), axis=1)\n",
    "df['config_lambda'] = df[['rang', 'epsilon', \"momentum\"]].apply(lambda x: ', '.join(x.astype(str)), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-20T21:45:18.033565Z",
     "start_time": "2020-10-20T21:45:18.020533Z"
    }
   },
   "outputs": [],
   "source": [
    "# Sauvegarder le fichier\n",
    "fichier_HyperFinaux = \"{:}_HyperparametresFinaux.ftr\".format(ch_fichier_experience)\n",
    "df.to_feather(fichier_HyperFinaux)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrainer le meilleur modèle\n",
    "\n",
    "* Choisir la combinaison d'hyperparamètres qui donne la plus petite erreur finale sur l'échantillon test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-20T21:45:18.065534Z",
     "start_time": "2020-10-20T21:45:18.035531Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rmse_test</th>\n",
       "      <th>rmse_train</th>\n",
       "      <th>rmse_gen</th>\n",
       "      <th>rang</th>\n",
       "      <th>epsilon</th>\n",
       "      <th>momentum</th>\n",
       "      <th>_lambda</th>\n",
       "      <th>config_rang</th>\n",
       "      <th>config_epsilon</th>\n",
       "      <th>config_momentum</th>\n",
       "      <th>config_lambda</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23.32767</td>\n",
       "      <td>23.325083</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0.01556</td>\n",
       "      <td>0.7772</td>\n",
       "      <td>0.7772</td>\n",
       "      <td>0.01556, 0.7772, 0.7772</td>\n",
       "      <td>20.0, 0.7772, 0.7772</td>\n",
       "      <td>20.0, 0.01556, 0.7772</td>\n",
       "      <td>20.0, 0.01556, 0.7772</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rmse_test  rmse_train rmse_gen  rang  epsilon  momentum  _lambda  \\\n",
       "0   23.32767   23.325083        0    20  0.01556    0.7772   0.7772   \n",
       "\n",
       "               config_rang        config_epsilon        config_momentum  \\\n",
       "0  0.01556, 0.7772, 0.7772  20.0, 0.7772, 0.7772  20.0, 0.01556, 0.7772   \n",
       "\n",
       "           config_lambda  \n",
       "0  20.0, 0.01556, 0.7772  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Plus petit RMSE sur l'ensemble de test\n",
    "min_test = df[df.rmse_test == df.rmse_test.min()]\n",
    "min_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-20T21:45:18.081536Z",
     "start_time": "2020-10-20T21:45:18.066534Z"
    }
   },
   "outputs": [],
   "source": [
    "## Mettre le rang et les time lag dans les init\n",
    "\n",
    "rang = np.int(min_test.rang)\n",
    "\n",
    "init_hyper = {\n",
    "    \"epsilon\": np.float(min_test.epsilon),\n",
    "    \"_lambda\": np.float(min_test._lambda),\n",
    "    \"momentum\": np.float(min_test.momentum)\n",
    "}\n",
    "\n",
    "param_utils = dict(rang=rang, init_hyper=init_hyper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-20T21:45:18.447005Z",
     "start_time": "2020-10-20T21:45:18.082537Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "ItÃ©rations:   0%|                                                                               | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "ItÃ©rations:  33%|███████████████████████▋                                               | 1/3 [00:00<00:00,  8.66it/s]\u001b[A\n",
      "ItÃ©rations:  67%|███████████████████████████████████████████████▎                       | 2/3 [00:00<00:00,  8.72it/s]\u001b[A\n",
      "ItÃ©rations: 100%|███████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00,  8.80it/s]\u001b[A\n",
      "                                                                                                                       \u001b[A"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "U, V, train_rmse_list, test_rmse_list, perfo_fin, etude_hyper = pmf(\n",
    "    train_vec=train_data,\n",
    "    val_vec=test_data,\n",
    "    num_feat=rang,\n",
    "    epsilon=param_utils[\"init_hyper\"][\"epsilon\"],\n",
    "    _lambda=param_utils[\"init_hyper\"][\"_lambda\"],\n",
    "    momentum=param_utils[\"init_hyper\"][\"momentum\"],\n",
    "    maxepoch=maxepoch,\n",
    "    num_batches=50,\n",
    "    batch_size=500,\n",
    "    max_early_stop=max_early_stop,\n",
    "    max_plateau_stop=max_plateau_stop)\n",
    "end = time.time()\n",
    "\n",
    "mat_hat = U @ V.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sauvegarder les informations sur l'entrainement du meilleur modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-20T21:45:18.462006Z",
     "start_time": "2020-10-20T21:45:18.449006Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'exp\\\\simulation_simple\\\\SimSimple_100_10_FMP_v001_r20-w15-x777-t777'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reformater cette case (!)\n",
    "ch_experience_finale = f\"{ch_fichier_experience}_r{param_utils['rang']}-w{int(param_utils['init_hyper']['epsilon']*1000)}-x{int(param_utils['init_hyper']['_lambda']*1000)}-t{int(param_utils['init_hyper']['momentum']*1000)}\"\n",
    "ch_experience_finale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sauvegarder la matrice prédite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-20T21:45:18.478118Z",
     "start_time": "2020-10-20T21:45:18.464007Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exp\\simulation_simple\\SimSimple_100_10_FMP_v001_r20-w15-x777-t777_prediction.mat\n"
     ]
    }
   ],
   "source": [
    "fichier_prediction = \"{:}_prediction.mat\".format(ch_experience_finale)\n",
    "save_mat_hat = {\"mat\": mat_hat}\n",
    "sio.savemat(fichier_prediction, save_mat_hat)\n",
    "tqdm.write(fichier_prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sauvegarder avec les nouvelles valeurs imputées\n",
    "\n",
    "* Garder la matrice de données originales et imputer seulement les valeurs manquantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-20T21:45:18.493119Z",
     "start_time": "2020-10-20T21:45:18.480122Z"
    }
   },
   "outputs": [],
   "source": [
    "index = np.where((mat_complet != 0) & (mat_binaire == 0))\n",
    "matrice_manquants = mat_manquants.copy()\n",
    "matrice_predite = mat_hat.copy()\n",
    "matrice_manquants[index] = matrice_predite[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-20T21:45:18.509119Z",
     "start_time": "2020-10-20T21:45:18.494119Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exp\\simulation_simple\\SimSimple_100_10_FMP_v001_r20-w15-x777-t777_imputation.mat\n"
     ]
    }
   ],
   "source": [
    "fichier_imputation = \"{:}_imputation.mat\".format(ch_experience_finale)\n",
    "save_mat_manquants = {\"mat\": matrice_manquants}\n",
    "sio.savemat(fichier_imputation, save_mat_manquants)\n",
    "tqdm.write(fichier_imputation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sauvegarder les information pour la présentation des résultats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-10T23:42:49.664881Z",
     "start_time": "2020-08-10T23:42:49.590881Z"
    }
   },
   "source": [
    "## Sauvegarder le tableau pour la comparaison intermodèles\n",
    "\n",
    "Éléments du tableau: \n",
    "- Performance du modèle (RMSE [entrainement, validation] et MAPE [validation])\n",
    "- Hyperparamètres utilisés (incluant le rang et autres paramètres d'intérêt)\n",
    "- Temps d'entrainement\n",
    "- Fichier d'entrainement (nom, dimensions, nombre de manquants, proportion de manquants)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-20T21:45:18.525120Z",
     "start_time": "2020-10-20T21:45:18.511123Z"
    }
   },
   "outputs": [],
   "source": [
    "dim1, dim2 = mat_complet.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-20T21:45:18.541119Z",
     "start_time": "2020-10-20T21:45:18.528122Z"
    }
   },
   "outputs": [],
   "source": [
    "base_manquants = len(np.where((mat_complet == 0))[0])\n",
    "entrainement_manquants = len(np.where((mat_binaire == 0))[0])\n",
    "obs_entrainement = len(np.where(mat_binaire != 0)[0])\n",
    "obs_test = len(np.where((mat_complet != 0) & (mat_binaire == 0))[0])\n",
    "obs_totales = dim1 * dim2\n",
    "lignes, colonnes = mat_complet.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-20T21:45:18.557124Z",
     "start_time": "2020-10-20T21:45:18.543124Z"
    }
   },
   "outputs": [],
   "source": [
    "temps_entrainement = end - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-20T21:45:18.572883Z",
     "start_time": "2020-10-20T21:45:18.558125Z"
    }
   },
   "outputs": [],
   "source": [
    "dict2 = {}\n",
    "\n",
    "dict2.update(\n",
    "    dict(modele=parametres[\"modele\"],\n",
    "         hyperparametres=str(param_utils),\n",
    "         rang=param_utils[\"rang\"],\n",
    "         test_rmse=perfo_fin[\"test_rmse\"],\n",
    "         test_mape=0,\n",
    "         train_rmse=perfo_fin[\"train_rmse\"],\n",
    "         gen_rmse=0,\n",
    "         temps=temps_entrainement,\n",
    "         nom_fichier=parametres[\"fichier_binaire\"],\n",
    "         lignes=lignes,\n",
    "         colonnes=colonnes,\n",
    "         obs_totales=obs_totales,\n",
    "         obs_test=obs_test,\n",
    "         obs_entrainement=obs_entrainement,\n",
    "         entrainement_manquants=entrainement_manquants,\n",
    "         base_manquants=base_manquants,\n",
    "         prop_manquants=parametres[\"manquants\"]))\n",
    "df_comparatif = pd.DataFrame(dict2, index=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-20T21:45:18.591684Z",
     "start_time": "2020-10-20T21:45:18.573886Z"
    }
   },
   "outputs": [],
   "source": [
    "# Sauvegarder le fichier\n",
    "fichier_comparatif = os.path.join(parametres[\"dossier_experience\"], \"fichier_comparatif.csv\")\n",
    "df_comparatif.to_csv(fichier_comparatif, mode='a', header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sauvegarder les données pour la présentation graphique\n",
    "* Données utilisées pour la formation du nuage de points (prédiction c. réelles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-20T21:45:18.704684Z",
     "start_time": "2020-10-20T21:45:18.593682Z"
    }
   },
   "outputs": [],
   "source": [
    "x_pred = mat_hat[index]\n",
    "y_original = mat_complet[index]\n",
    "\n",
    "df_comparaison = pd.DataFrame([x_pred, y_original]).T\n",
    "df_comparaison.columns = ['x_pred', 'y_original']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-20T21:45:18.719682Z",
     "start_time": "2020-10-20T21:45:18.705680Z"
    }
   },
   "outputs": [],
   "source": [
    "fichier_comparaison = \"{:}_comparaison.ftr\".format(ch_experience_finale)\n",
    "\n",
    "df_comparaison.to_feather(fichier_comparaison)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-20T21:45:18.735715Z",
     "start_time": "2020-10-20T21:45:18.722681Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exp\\simulation_simple\\SimSimple_100_10_FMP_v001_r20-w15-x777-t777_comparaison.ftr\n"
     ]
    }
   ],
   "source": [
    "tqdm.write(fichier_comparaison)"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table des matières",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "307.194px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
